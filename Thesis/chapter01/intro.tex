We as humans have always shared a curiosity about the future.  As we become
more and more dependent upon computers as they permeate their way into our
daily lives, the software that controls these machines is ultimately still
subject to human error.  Some of these system are responsible for sustaining
human life and ultimately are not protected from that same human error.
Consequently, under the wrong circumstances a machine failure could result
in loss of human life.  Critical infrastructure and Air Force missions depend
on the reliability of computer systems.  As a result, being able to predict
pending failue in computer systems can offer tremendous and potentially
life-saving applications in todays technologically advanced world.  While
actually being able to accurately predict failure has unfortunately not been
proven possible, there has been an enormous amount of time and energy spent
over the past several decades attempting to make educated predictions about the
failure of machines through the use of sophisticated machine learning
algorithms.  In this research we explore the application of a new framework
developed to automatically re-train machine learning based failure predictors.
There a number of ways to reduce the number of errors produced by a piece of
software, but the software development life-cycle is shrinking and less time
and effort are being devoted to reducing errors before deployment.  This leaves
real-time error prevention or handling.  

In recent years, it seems many of the cloud based computing companies have
attempted to solve this problem by making all of their services massively
redundant.  As hardware becomes more affordable, this is an effective approach
in many ways but ultimately is still not cost efficient.  In some cases, funds
may not be available to acheive this sort of redundancy.  Consequently, this
research focuses on a small piece of the general field of reliable computing:
online failure prediction (OFP).  OFP is the act of attempting to predict when
failures are likely so that they can be avoided.  A great deal of work has been
done in this field which we outline in chapter~\ref{chapter2}, but much of it
has gone unimplemented due to the complex and manual task of training a
prediction model.  If the underlying system changes at all (which in todays
world is a common occurrence due to the aforementioned shrinking software
development life-cycle) the efficacy of a prediction model can be drastically
reduced if not rendered completely useless until it is retrained.  This
research explores an implementation of a new framework for automatically
retraining a predictor after such an underlying system change.  More
specifically, we present our results after implementing this framework using a
Microsoft Windows Server domain controller.  We then apply successive software
updates until the model we have selected becomes useless and allow the
framework to re-train our predictor.

\section{Problem Statement}
Predicting and alerting on impending network service failures currently uses
thresholds and rules on discrete items in enterprise system logs.  For example,
if the central processing unit (CPU) and memory usage on a device exceeds 90\%,
then an alert may be issued.  This approach works, but only for certain types
of failures and in order to minimize the false positives, it only makes
recommendations minutes before a failure, or when the system is in an already
degraded performance mode.  To maintain network resilience, the operational
organizations responsible for communications support desperately need some
means of gaining lead-time before a service failure occurs.  

Preceding a service failure event, multiple indicators spread disparate
sources, perhaps over a long period of time, may appear in system logs.  The
log entries of interest are also quite rare compared with normal operations.
Because of these constraints, identifying failure indicators can be nearly
impossible for humans to perform.  Further, in most cases, restoring service is
more important than identifying the indicators that may or may not have
existed.  

Failure prediction can be approached in many ways. Arguably the simplest
approach is to use everyday statistical analysis to, for example, determine the
mean time between failures of specific components. The analysis of all
components making up a system can be aggregated to make predictions about that
system using a set of statistics-based or business-relevant rules.
Unfortunately, the complexity of modern architectures has outpaced such
off-line statistical-based analysis, which has driven the advancement of OFP.
OFP differs from other means of failure prediction in that it focuses on
classifying the current running state of a machine as either failure prone or
not, or in such a way that it describes the confidence in how failure prone a
system is at present~\cite{salfnerSurvey}.

Unfortunately, in recent years much of the work in OFP has gone unused due to
the dramatic decrease in cost and complexity involved in building
hardware-based redundant systems.  Furthermore, in most cases OFP implements
machine learning algorithms that require manual re-training after underlying
system changes.  More troubling is that these system changes are becoming more
frequent as the software development life cycle moves toward a more continuous
integration model.  To help solve these challenges, the framework presented
in~\cite{irrera2015} uses simulated faults to automatically re-train a
prediction algorithm to make implementing OFP approaches easier.  We propose to
expand the work in~\cite{irrera2015} to capture developments since its writing
and generalize it so it works for a broader class of devices.

\section{Impact of Research}
Every day, many of the Air Force's critical missions depend on our computer
infrastructure.  An essential piece of this infrastructure is the
authentication mechanisms that protect our sensitive information.
Unfortunately, the software at the core of this infrastructure is written and
maintained by humans and thus susceptible human error.  This research will
enable the Air Force and many others that use the Microsoft Enterprise
Infrastructure to accurately predict pending service outages thereby providing
lead-time in order to avoid those outages.  The result is cost savings in
personnel, equipment, but isn't limited to cost savings.  It is difficult to
quantify the risk of mission failure due to network service outage.

\section{Assumptions and Limitations}
As previously stated, it has not been proven possible to accurately predict
future events without a priori knowledge.  As a result, this research depends
on the fact that there are indicators of failure present and available to us
with enough lead-time to accurately make decisions and take mitigation action
should failure be predicted based on these indicators.  This research presents
a method of predicting failure, but this method is completely useless at
predicting \emph{act of God} events.  Further, this method is capable of
predicting failure based on software failures and cannot provide any useful
information about malicious attacks against the target software.

\section{Expected Results of Research}
Because a prediction method is not presently deployed on any Air Force network,
any level of dependable prediction will be better than what is currently
available.  This research will attempt to show that after an underlying system
change, this method of predicting failure will be capable of automatically
training a more effective prediction algorithm so that this technique can be
implemented on an Air Force network with little to no impact on manpower.
Consequently, we expect that this research will inform decision makers and
allow them to implement this technique in a production environment.

Specifically, we believe the technique presented in this research could most
effectively be implemented and used by the Cyber Security and Control System
(CSCS) weapon system employed at the 561st and 83d Network Operation Squadrons
(NOS) and their associated detachments to reduce the number of network service
outages, increasing uptime, leading to improved mission effectiveness in both
the support and operational domains.  Further, we believe this technique
general enough to be employed outside of the Air Force to increase mission
effectiveness across the Department of Defense (DOD).  External to the DOD,
this research further generalizes an approach that could be used to help
increase availability of nearly any computer system.
