\subsection{Definitions} \label{definitions}
\subsubsection{Proactive Fault Management:} \label{pfm}
Salfner, et al.~\cite{salfnerSurvey} define proactive fault management (PFM) as
the process by which faults are handled in a proactive way, analogous with
\emph{fault tolerance} and basically consisting of four steps: online failure
prediction, diagnosis, action scheduling, and action execution as shown in
Figure~\ref{fig:proactiveFaultManagement}.
The final three stages of PFM define how much lead time is required to avoid a
failure when predicted during OFP.  \emph{Lead time} is defined as the time
between when failure is predicted and when that failure will occur.  Lead time
is one of the most critical elements of a failure prediction approach.

\figproactiveFaultManagement

OFP is defined as the first step in PFM shown in
Figure~\ref{fig:proactiveFaultManagement}.  OFP is the act of analyzing the
running state of a system in order to predict a failure in that system. Once
failure has been predicted, a fault tolerant system must determine what will
cause the failure.  This stage is called the \emph{diagnosis} stage or
``root-cause analysis'' stage.  During the \emph{diagnosis} stage, the analysis
must be conducted so that a system knows which remediation actions are
possible.  After it is determined what will cause a failure, a fault tolerant
system must schedule a remediation action that is either performed by an
operator or done automatically.  This stage is known as the \emph{action
scheduling} stage and normally takes as input the cost of performing an action,
confidence in prediction, effectiveness/complexity of remedy action and makes a
decision about what action to perform based on that input.  In some cases a
remedy action can be so simple that even if the confidence in the prediction is
low, the action can still be performed with little impact on the overall system
and its users.  A thorough analysis of the trade-off between cost of avoidance
and confidence in prediction and the associated benefits is described
in~\cite{candea2004microreboot}.  Finally, in order to avoid failure, a system
must execute the scheduled remediation action or let an operator know which
actions can be taken in a stage called \emph{action execution}.

\subsubsection{Faults, Errors, Symptoms, and Failures:}
This research uses the definitions from~\cite{avivzienis2004basic} as
interpreted and extended in~\cite{salfnerSurvey} for the following terms:
failure; error (detected versus undetected); fault; and symptom.

\emph{Failure} is an event that occurs when the delivered service deviates from
correct service.  In other words, things can go wrong internally; as long as
the output of a system is what is expected, failure has not occurred.  

An \emph{error} is the part of the total state of the system that may lead to
its subsequent service failure.  \emph{Errors} are characterized as the point
when things go wrong~\cite{salfnerSurvey}.  Fault tolerant systems can handle
errors without necessarily evolving into failure.  There are two kinds of
errors.  First, a \emph{detected error} is an error that is reported to a
logging service.  In other words, if it can be seen in a log then it is a
detected error.  Second, \emph{undetected errors} are errors that have not been
identified by an error detector.  Undetected errors are things like memory
leaks.  The error exists, but as long as there is usable memory, it is not
likely to be reported to a logging service.  Once the system runs out of usable
memory, undetected errors will likely appear in logs and become a detected
errors.  A \emph{fault} is the hypothesized root cause of an error.  Faults can
remain dormant for some time before manifesting themselves and causing an
incorrect system state.  In the memory leak example, the missing \emph{free}
statement in the source code would be the fault.  

A \emph{symptom} is an out-of-norm behavior of a system's parameters caused by
errors, whether detected or undetected.  In the memory leak example, a possible
symptom of the error might be delayed response times due to sluggish
performance of the overall system.

\figfailureFlowDiagram

Figure~\ref{fig:failureFlowDiagram} illustrates how a software fault can evolve
into a failure.  Faults, errors, symptoms, and failures can be further
categorized by how they are detected also shown in
Figure~\ref{fig:failureFlowDiagram}.  Salfner, et al.~\ref{salfnerSurvey}
introduces a taxonomy of OFP approaches and classifies failure prediction
approaches by the stage at which a fault is detected as it evolves into a
failure: auditing, reporting, monitoring, and tracking.  Testing is left out
because it does not help detect faults in an online sense.  

\figonlinePrediction

Figure~\ref{fig:onlinePrediction} demonstrates the timeline associated with
OFP.  The parameters used by the community to define a predictor are as
follows:
\begin{itemize}
	\item{Present Time: $t$}
  \item{Lead Time: $\Delta t_{l}$, is the total time at which a predictor makes
  an assessment about the current state.}
  \item{Data Window: $\Delta t_{d}$, represents the time from which data is
  used for a predictor uses to make its assessment.}
  \item{Minimal Warning Time: $\Delta t_{w}$, is the amount of time required to
  avoid a failure if one is predicted.}
  \item{Prediction Period: $\Delta t_{p}$, is the time for which a prediction
  is valid.  As $\Delta t_{p} \rightarrow \infty$, the accuracy of the
  predictor approaches 100\% because every system will eventually fail.  As
  this happens, the usefulness of a predictor is diminished.}
\end{itemize}

As the above parameters are adjusted, predictors can become more or less
useful.  For example, it is clear that as a predictor looks further into the
future potentially increasing \emph{lead time}, confidence in its prediction is
likely to be reduced.  On the other hand, if \emph{lead time} is too small,
there will likely not be enough time to effectively take remediation action.
In general, OFP approaches seek to find a balance between the parameters,
within an acceptable bound depending on application, to achieve the best
possible performance.
