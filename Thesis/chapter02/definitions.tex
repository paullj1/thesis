\subsection{Definitions} \label{definitions}
\subsubsection{Proactive Fault Management:} \label{pfm}
Figure~\ref{fig:proactiveFaultManagement} shows the components in the PFM process, and in that process the final three stages deine how much lead time is required to avoid a failure when predicted during OFP. Lead time, although defined later, is a critical element in any approach to OFP.  

\figproactiveFaultManagement

Although there is a lot of utility in studying PFM in its entirety, the crux to its success is at the beginning of this four stage process.  This research focusses mainly on that first step however, we include here a brief overview of the remaining steps as they define how much \emph{lead time} is required to avoid a predicted failure in order for the first step (OFP) to be of any use.  \emph{Lead time} is formally defined later in this section, but it should be noted now that it is a critical element of a failure prediction approach.

OFP is defined as the first step in PFM seen in Figure~\ref{fig:proactiveFaultManagement}.  The last three stages of PFM are diagnosis, action scheduling, and action execution.  Once failure has been predicted, a fault tolerant system must determine what will cause the failure.  This stage is called the \emph{diagnosis} stage or ``root-cause analysis'' stage.  During the \emph{diagnosis} stage, the analysis must be conducted so that a system knows which remediation actions are possible.  After it is determined what will cause a failure, a fault tolerant system must schedule a remediation action that is either performed by an operator or done automatically.  This stage is known as the \emph{action scheduling} stage and normally takes as input the cost of performing an action, confidence in prediction, effectiveness/complexity of remedy action and makes a decision about what action to perform based on that input.  In some cases a remedy action can be so simple that even if the confidence in the prediction is low, the action can still be performed with little impact on the overall system and its users.  A thorough analysis of the trade-off between cost of avoidance and confidence in prediction and the associated benefits is described in~\cite{candea2004microreboot}.  Finally, in order to avoid failure, a system must execute the scheduled remediation action or let an operator know which actions can be taken in a stage called \emph{action execution}.

\subsubsection{Faults, Errors, Symptoms, and Failures:}
As~\cite{salfnerSurvey} points out, many attempts have been made to define faults, errors, symptoms, and failures.  In this research we use the definitions from~\cite{avivzienis2004basic} as interpreted and extended in~\cite{salfnerSurvey} for the following terms: failure; error (detected versus undetected); fault; and symptom.

\emph{Failure} is an event that occurs when the delivered service deviates from correct service.  In other words, things can go wrong internally; as long as the output of a system is what is expected, failure has not occurred.  An \emph{error} is the part of the total state of the system that may lead to its subsequent service failure.  \emph{Errors} are characterized as the point when things go wrong~\cite{salfnerSurvey}.  Fault tolerant systems can handle errors without necessarily evolving into failure.  There are two kinds of errors.  First, a \emph{detected error} is an error that is reported to a logging service.  In other words, if it can be seen in a log then it is a detected error.  Second, \emph{undetected errors} are errors that have not been identified by an error detector.  Undetected errors are things like memory leaks.  The error certainly exists, but as long as there is usable memory, it is not likely to be reported to a logging service.  Once the system runs out of usable memory, undetected errors will likely show up in logs and become a detected errors.  A \emph{fault} is the hypothesized root cause of an error.  Faults can remain dormant for some time before manifesting themselves and causing an incorrect system state.  In the memory leak example, the missing \emph{free} statement in the source code would be the fault.  A \emph{symptom} is an out-of-norm behavior of a system's parameters caused by errors, whether detected or undetected.  In the memory leak example, a possible symptom of the error might be delayed response times due to sluggish performance of the overall system.

\figfailureFlowDiagram

Figure~\ref{fig:failureFlowDiagram} illustrates the differences between faults, errors, symptoms and failures.  It further shows how faults can evolve into failures and how specifically at each of the steps, they can be detected.  We define these specifically because in Section~\ref{approaches} we outline a taxonomy of OFP approaches introduced in~\cite{salfnerSurvey} which divides the OFP approaches into four major categories based on the four methods for detecting errors in running systems: auditing, reporting, monitoring, and tracking.

\figonlinePrediction

Figure~\ref{fig:onlinePrediction} demonstrates the timeline associated with OFP.  It does so based on a set of parameters drawn from the literature from the work in~\cite{salfnerSurvey}.  The parameters used by the community to define a predictor are as follows:
\begin{itemize}
	\item{Present Time: $t$}
	\item{Lead Time: $\Delta t_{l}$, is the total time at which a predictor makes an assessment about the current state.}
	\item{Data Window: $\Delta t_{d}$, represents the time from which data is used for a predictor uses to make its assessment.}
	\item{Minimal Warning Time: $\Delta t_{w}$, is the amount of time required to avoid a failure if one is predicted.}
	\item{Prediction Period: $\Delta t_{p}$, is the time for which a prediction is valid.  As $\Delta t_{p} \rightarrow \infty$, the accuracy of the predictor approaches 100\% because every system will eventually fail.  As this happens, the usefulness of a predictor is diminished.}
\end{itemize}

As the above parameters are adjusted, predictors can become more or less useful.  For example, it is clear that as we look further into the future potentially increasing \emph{lead time}, our confidence in our prediction is likely to be reduced.  On the other hand, if \emph{lead time} is too small, we may not be able to effectively implement a remediation action.  In general, OFP approaches seek to find a balance between the parameters, within an acceptable bound depending on application, to achieve the best possible performance.
