\chapter{Methodology} \label{chapter3}
The purpose of the \ac{AFP} framework is to automate the generation of
realistic labelled failure data for the purposes of automatically training a
failure prediction algorithm.  The framework breaks down into modules so that
it can be more easily adapted for different applications.  This chapter
presents three topics.  The first describes the process that the framework
executes in order to generate the labelled training data and train a failure
prediction algorithm.  The second describes each module of the extended
\ac{AFP} framework.  The final section outlines extensions to the \ac{AFP} not
covered in the other two sections.

This chapter outlines the implementation and extensions to the \ac{AFP}
Framework~\cite{irrera2015} as well as an experiment to validate those
extensions and further generalize the framework.  The \ac{AFP} was originally tested
on a single system running an operating system that has been deprecated.
Consequently, the results from the case study conducted using the \ac{AFP} are
limited in utility and require generalization to be useful to the general
community.

\section{Failure Data Generation} \label{sec:generation}
This work extends the \ac{AFP} framework~\cite{irrera2015} by conducting
another case study with an \ac{MS} Windows Server acting as an \ac{AD} service
with a more representative fault load as well as a new implementation of the
\ac{G-SWFIT} technique for the x86-64 architecture.  The case study is done
using three new types of faults: third-party memory leak, third-party \ac{CPU}
hog, and process memory corruption.  For completeness, the standard
\ac{G-SWFIT} technique is also used.  Finally, findings are reported after
implementing this framework using two different statistical machine learning
techniques: boosted decision trees and \ac{SVM}.  In both cases, feature
reduction is performed as is done by Fulp et al.~\cite{fulp2008}, on a sliding
time window as is done by Irrera, et al.~\cite{irrera2013a} and
Vaarandi~\cite{vaarandi2002}.

This section outlines the step-by-step procedure by which the extended \ac{AFP}
is evaluated to show how effective it is when used on Windows Server
deployments.  This is done by dividing the steps taken in an experiment into
the three major phases as defined in~\cite{irrera2015}: preparation phase,
execution phase, and training phase.

\subsection{Preparation Phase}
In this phase the \ac{AFP} is prepared to run for the first time as described
in~\cite{irrera2015}.  The \ac{CRISP-DM}~\cite{crispdm} should be applied to
this situation when evaluating how to best apply the \ac{AFP} for a particular
target.  For the purposes of this research, our focus is on the \ac{MS}
Windows Directory Services and predicting failure in those services.  To
demonstrate the efficacy of the \ac{AFP}, a predictor must be evaluated before
and after a significant software update.  As a result, the most critical
preparation made in evaluating this framework is to hold back all software
updates on the target system prior to the first run of the execution phase.
The performance of various prediction techniques will be evaluated both before
and after the Windows Update is allowed to run.  A complete list of the updates
installed is shown in Appendix~\ref{app:updates}.

This phase is ultimately the manual act of implementing the framework.  Each
module of the implementation for this work is detailed in
Section~\ref{sec:implementation} and is therefore not discussed further here.  

\subsection{Execution Phase}
A general outline of this phase is shown in Figure~\ref{fig:ExecutionPhase}.
This phase is divided into three major steps: data collection and failure
prediction, event checking, and training/update as described in this section.

\figExecutionPhase{2.5in}

\subsubsection{Data Collection and Failure Prediction}
In this phase, the system has a working predictor providing input to some sort
of decision system.  It should be noted here that this decision system does not
have to be automated.  The system in this phase is making failure predictions
about the current state based on the last run of the training phase.  This
function is not implemented in this research as it is application specific.
The output of this process in this experiment is a warning message which
indicates failure.

\subsubsection{Event Checking}
Concurrent with the data collection and failure prediction sub-phase, the
\ac{AFP} continuously monitors events that may alter the underlying system.
For this experiment, these events are software updates.  The output of each
episode of this phase is a binary decision to either begin the training phase,
or not.  In this experiment, the training phase is manually triggered upon
completion of a major software update.

\subsubsection{Failure Predictor (Re-)Training and Update}
The purpose of this sub-phase is to initiate the training phase and compare its
results (a new predictor) with the currently employed predictor.  Should the
new predictor perform better, the old predictor is replaced by the new.

\subsection{Training Phase}
The training phase is broken down into five major steps:  target replication,
data generation \& collection, dataset building, predictor training, and
analysis.  The general flow is shown in Figure~\ref{fig:TrainingPhase}.  Each
phase is outlined in the following sub-sections.

\figTrainingPhase{4in}

\subsubsection{Target Replication}
During this phase a virtual clone of the target is made.  After the clone is
made, the fault injection and monitoring software is installed.  In this
experiment, the monitoring tool is the same as on the production system but
care must be taken to ensure the host-name is changed so the log messages
generated during this phase are not confused with messages from the production
system.

\subsubsection{Data Generation \& Collection}
The purpose of this phase is to generate the data to train a new prediction
algorithm.  As a result, this sub-phase must be executed several times to
generate statistically meaningful datasets.  In this phase, the controller
triggers the cloned target startup.  Once startup is complete and the system
enters an idle state, the monitoring tool begins collecting data from the
target.  After monitoring has begun, the workload is started.  Once the
workload has entered a steady state, the fault load is started.  Finally, when
failure occurs, monitoring stops, the workload stops, and the system is
rebooted for the next run.  To generate golden data (or data with no failures
present to aid training), the first run omits the fault injection step.

The most critical part of this process is labelling the data when failure
occurs.  For the purposes of this experiment, failure is defined by the log
message ID $4625$: An account failed to log
on\footnote{\url{https://support.microsoft.com/en-us/kb/977519}}.  When this
occurs in conjunction with known valid credentials on an account that is not
disabled, the preceding data window defined for the experiment is labelled as
failure prone.  Additionally, the workload generator used in this research
reports when authentication fails and transmits a syslog message to the
controller.  

\subsubsection{Dataset Building}
In this phase, the raw syslog messages are formatted and encoded to train the
prediction model.  The purpose of this phase is to prepare the raw messages to
be used as numeric inputs for the training phase.  Irrera, et
al.~\cite{irrera2015} loaded all event messages into a database for processing.
In this work, the events are initially stored in a flat file on the Ubuntu
machine by the syslog daemon.  The raw log messages appear in a flat text file
as follows:

\begin{lstlisting}
May  8 14:31:52 dc.afnet.com MSWinEventLog 5 Security 3 Sun May 08 14:31:50 2016 4672 Microsoft-Windows-Security-Auditing  N/A Audit Success dc.afnet.com 12548 Special privileges assigned to new logon.  Subject:  Security ID:  S-1-5-21-2379403389-181978965-2953995107-500  Account Name:  Administrator  Account Domain:  AFNET  Logon ID:  0x9beb4e7a  Privileges:  SeSecurityPrivilege    SeBackupPrivilege    SeRestorePrivilege    SeTakeOwnershipPrivilege    SeDebugPrivilege    SeSystemEnvironmentPrivilege    SeLoadDriverPrivilege    SeImpersonatePrivilege    SeEnableDelegationPrivilege
\end{lstlisting}

The messages are formatted using the
\emph{Snare}\footnote{\url{http://wiki.rsyslog.com/index.php/Snare\_and\_rsyslog}}
MSWinEventLog format which can be divided into several categories.  The first
is the time-stamp and host name of the sender prepended by the syslog server
daemon: \emph{May 8 14:31:52 dc.afnet.com}.  The remainder of the message
contains tab delimited values where the keys (and consequent features) are
shown in Table~\ref{tab:message}.  Of these features, Criticality,
EventLogSource, EventID, SourceName, and CategoryString are selected for
further encoding.

\tabMessage

The raw messages are then encoded.  First, the events are filtered by EventID
as is done by Fulp et al.~\cite{fulp2008} to reduce the noise generated by
successful login attempts.  Log messages with IDs shown in
Table~\ref{tab:messageIDs} are filtered from the input.  

Next, to encode the time dimension and reduced the sequential message ordering
dependency, a sliding time window is created by counting each unique entry for
each feature within the data window ($\delta t_d$) as is done by
Vaarandi~\cite{vaarandi2002}.  During this stage, the number of messages that
were reported in the data window is also recorded and used as a feature.

Finally, each time window preceding the failure within $\delta t$ is labelled
as failure prone as is done by Irrera, et al.~\cite{irrera2015}.  This encoding
enables the use of classification algorithms in the training phase.  An example
of the final encoding is shown in Table~\ref{tab:window}.

\tabMessageIDs % Keep these together (footnote)
\footnotetext{\url{https://support.microsoft.com/en-us/kb/977519}}
\tabSlidingWindow

\subsubsection{Predictor Training}
The purpose of this phase is to use the data generated by the forced failure of
the virtual clone to train a machine learning algorithm to classify a system as
failure prone or not.  

During this phase, each of the $k$ datasets produced by the $k$ runs of the
execution phase, each containing a single failure, are used to train a
statistical classification model.  Each dataset is an $n \times p$ matrix where
$n$ is the number of sliding time windows and $p$ is the number of predictors
present in the output of the dataset building phase.  These $k$ datasets are
used to conduct a $k - 1$-fold cross validation training and evaluation process
where the first $k - 2$ datasets are used to train the statistical model.  The
remaining set is used to validate the trained model.  The data is then rotated
and repeated $k - 1$ times.  Parameters for the classification model are
selected based on the output of this cross validation.  Finally, statistics and
performance are reported on the final model's performance on the held out data
set.

\subsubsection{Analysis}
During this phase, the precision, recall, f-measure, and area under the
\ac{ROC} curve are computed using the figures measured in the previous phase so
that the new predictor can be compared against the old.  If a new predictor
outperforms the old, the old is replaced with the new.  Upon completion of this
phase, control flow returns to the \emph{Event Checking} phase.

\section{Implementation of the \ac{AFP}} \label{sec:implementation}
\subsection{\ac{AFP} Framework Implementation}
This experiment replicates the experiment in~\cite{irrera2015} except in place
of the web-server an \ac{MS} Windows Server running \ac{AD} Domain Services.
In addition, several extensions to the original experiment are made and
presented here.  Multiple prediction techniques have been applied using this
framework to further generalize and validate the framework.  The original
\ac{AFP} architecture is shown in Figure~\ref{fig:annotatedAFP} with the parts
that are modified in this work highlighted.  

\subsection{\ac{AFP} Modules}
Irrera, et al.~\cite{irrera2015} outline multiple modules into which they have
broken the \ac{AFP} Framework for organizational purposes.  This research does
not modify these modules, instead, it takes a more granular approach and
presents a modified architecture and details each element of that architecture.

\figannotatedAFP  

The following sections detail the virtual environment in which this
architecture was constructed.  For reference, this virtual environment was
hosted on two VMWare ESXi 5.5 hypervisors each with two 2.6 \ac{GHz} AMD
Opteron 4180 (6 cores each) \ac{CPU}s and 64 \ac{GB} memory.  The individual
\ac{VM}s are described in Tables~\ref{tab:hyp1}, and \ref{tab:hyp2}.

\tabHypervisorOne
\tabHypervisorTwo

\setcounter{secnumdepth}{5}

\subsection{Controller Hypervisor} \label{sec:controller} % 3.X.1
The controller functions in this experiment are split between two systems on a
single hypervisor shown in Table~\ref{tab:hyp2}.  One system is an \ac{MS}
Windows Server responsible for workload management and fault injection
management.  The additional Windows server also hosts remote desktop services
to allow the load generator to execute third party authentication with the
\ac{DC}.  The other system is an Ubuntu 14.04 server that performs the failure
prediction management and event management.  Each of these functions is
detailed in the following sections.

\subsubsection{Failure Prediction} \label{sec:failurePrediction} % 3.X.1.1
The failure prediction module predicts failure using machine learning
algorithms trained using the labelled training data generated by the rest of
this framework.  This module is constantly either training a new predictor
because a software update occurred, or predicting failure based on log messages
and possibly other features produced by the production system.

The \ac{AFP} failure prediction function as outlined in~\cite{irrera2015}, is
performed by a \ac{SVM} predictor using \emph{libsvm}.  Additionally, the
original experiment made use of a database that stored the features and
observations used for the failure prediction training algorithm.  This
experiment does not modify the failure prediction module drastically as it has
already been shown in previous work that the \ac{OFP} area of study is well
explored~\cite{salfnerSurvey}.  This research makes use of a different tool-set
to execute the training and predicting phases.  Due to its widespread use in
the statistical community~\cite{islr}, the prediction and training algorithms
make use of the \emph{R} programming language.

\subsubsection{Fault Injection} \label{sec:faultInjectionMgr}
This module is responsible for managing the fault load used to create realistic
failure data.  Irrera, et al.~\cite{irrera2015} use a single tool implementing
the \ac{G-SWFIT} for this module and pointed out that this module is the most
critical piece of the \ac{AFP} implementation.  \ac{G-SWFIT} was developed by
Duraes, et al.~\cite{gswfit} to emulate software failures for the purposes of
software testing.  The method is widely implemented for use in software fault
injection both commercially and
academically~\cite{natella2010,irrera2014,cotroneo2012,umadevi2015}.  

Recently, studies have questioned the representativeness of the failures
generated by \ac{G-SWFIT}~\cite{kikuchi2014,cotroneo2012}.  In each case, the
workload generated was critical in creating representative faults.  This
concern has been addressed in this research and is discussed in
Section~\ref{sec:workloadMgr}.

An additional concern regarding fault injection has been that some injected
faults may not elude modern software testing and as a result never actually
occur in production software~\cite{natella2010}.  The recommended remedy is to
conduct source code analysis to determine which pieces of code get executed
most frequently and avoid fault injection in those areas.  Unfortunately, the
target of this research is not an open source project and as a result, some of
the faults and resulting failures may never happen in a production environment.
Fortunately, the fault injection tool that has been developed for this research
automatically scans each library loaded by the target executable for fault
injection points and then is capable of evenly distributing the faults it does
inject.

Because of the concerns with fault injection, this research implements three
additional types of fault load that more exhaustively represents realistic
faults that may be encountered by a target process.  This experiment trains a
predictor using failures generated by third-party applications purposefully
written to slowly consume all available resources on a target system.
Specifically, the third-party application contains a memory leak that slowly
allocates all free system memory until the target application crashes.  Next,
failures are recorded as the result of a third-party application consuming all
\ac{CPU} time.  Source code for this application is included in
Appendix~\ref{app:resourceLeak}.  Finally, failure is recorded after corrupting
heap space in memory (versus program memory as done by the \ac{G-SWFIT}).  This
type of fault could be caused by privileged third party applications writing to
the target processes allocated memory.  Finally, for completeness, this
experiment uses a tool developed for this work that implements the \ac{G-SWFIT}
technique.

This work introduces an x86-64 implementation of the \ac{G-SWFIT} technique
called \ac{W-SWFIT} for Windows Software Fault Injection Tool.  The source code
for \ac{W-SWFIT} has been published as open source on
Github\footnote{\url{https://github.com/paullj1/w-swfit/}} so that others may
use it for any of the reasons cited in the original \ac{G-SWFIT}
paper~\cite{gswfit}.  For completeness, the source is also included in
Appendix~\ref{app:wswfit}.  

For this research, the original plan was to use the same fault injection tool
used in the original case study by Irrera, et al.~\cite{irrera2015}.
Unfortunately, that tool, and all prior \ac{G-SWFIT} implementations were
incapable of injecting faults into x86-64 binary executables.  Further, many of
the commercial products that were evaluated for this research were incapable of
dealing with modern \ac{ASLR}.  As a result, \ac{W-SWFIT} was developed for
this research and is capable of injecting faults into all user and kernel mode
applications on modern \ac{MS} Windows operating systems.  

The key contributions of \ac{W-SWFIT} are \ac{ASLR} adaption, the x86-64
translations that have performed.  Further, as pointed out by Irrera, et
al.~\cite{irrera2013a}, prior implementations of the \ac{G-SWFIT} were not
capable of injecting faults into protected (kernel mode) processes.  Since the
focus of this research is on a protected system process, this capability was
critical, and as a result, \ac{W-SWFIT} was implemented in a way that made
protected process injection possible.  

\ac{G-SWFIT} works by scanning binary libraries already in memory for patterns
(or operators) that match compiled errors made during development.  The faults
were based on the Orthogonal Defect Classification~\cite{bridge1998} and are
shown in~\ref{tab:faults}.  As pointed out by Salfner, et
al.~\cite{salfnerSurvey} Duraes, et al.~\cite{gswfit}, failures are ultimately
the result of software developer errors.  Unfortunately, \ac{G-SWFIT} has only
previously been implemented for Java
applications~\cite{sanches2011jswfit,martins2002jaca}, and the IA32 instruction
set~\cite{gswfit}.  The target application in this research is strictly an
x86-64 (also known as x64 or amd64) application and the patterns identified
previously are incompatible.  Consequently, a fault injection tool capable of
mutating x86-64 instructions in the same way was required.  \ac{W-SWFIT}
implements two of the operators in~\cite{gswfit} in the x86-64 language by
translating the operators shown in Table~\ref{tab:faults} from IA32 to x86-64.
The translation of these operators was not trivial given the complexity of the
x86-64 architecture.  However, a simple example is shown using the entry/exit
points of a function in Tables~\ref{tab:translationThirtyTwo},
and~\ref{tab:translationSixtyFour}.  The rest of the translations were done
using the \emph{Capstone}~\footnote{\url{http://www.capstone-engine.org}}
library and can be seen in source code for \ac{W-SWFIT}.

\tabFaults
\tabTranslationThirtyTwo
\tabTranslationSixtyFour

\subsubsection{Workload Managmement} \label{sec:workloadMgr} 
The Workload module creates realistic work for the target system in the sandbox
hypervisor to accomplish as a way of generating computational load.  Without
this module, it could take too long for an injected fault to evolve into a
failure.  Consider a missing \emph{free} statement and the consequent memory
leak.  A production target server may have a considerable amount of memory and
the leak could be very small.  To accelerate the possibility of failure
occurring, realistic load must be generated against the sandbox clone of the
production target.

In the original \ac{AFP} case study, a Windows XP based web-server was used for
a target and the load generation was done by a simple web request
generator~\cite{irrera2015}.  As previously mentioned, realistic workload is
critical in generating realistic failure and consequently training a useful
predictor.  Initial searches for a load generator suitable for this research
yielded a tool developed by \ac{MS} that initiated remote desktop connections
to aid in sizing a terminal services
server\footnote{\url{http://www.microsoft.com/en-us/download/details.aspx?id=2218}}.
By executing a remote desktop session, the authentication and \ac{DNS}
functions of the \ac{DC} would also be loaded.  Unfortunately, this tool is no
longer maintained and would not execute on the target
machine\footnote{\url{https://social.technet.microsoft.com/Forums/windowsserver/en-US/2f8fa5cf-3714-4eb3-a895-c30e2b26862d/debug-assertion-failed-sockcorecpp-line-623}}.
Further searches for tools that would sufficiently load the \ac{DC} did not
produce any results.  Consequently, a tool to produce realistic load for a
\ac{DC} was developed for this research and is introduced here.

The \ac{D-PLG} is a collection of \ac{MS} PowerShell scripts designed to
generate realistic traffic that will sufficiently load an \ac{MS} \ac{DC}.
Other network traffic generators typically work by replaying traffic captured
on a live network.  Unfortunately, due to the cryptographic nature of
authentication, simply replaying traffic will not load a service since the
timestamps and challenge responses will no longer be valid.  As a result, any
replayed traffic will be dropped and ignored by a live \ac{DC}.  \ac{D-PLG}
solves this problem by making native authentication requests by use of built-in
PowerShell cmdlets (command-lets).  By doing this, realistic authentication
requests are sent to the \ac{DC} and are actually processed.  The functions
performed by the \ac{DC} have been evaluated and \ac{D-PLG} is designed to
sufficiently load each of the services responsible for performing those
functions.

In this experiment, the \ac{DC} is configured as it is in many production
environments.  After careful analysis, it has been determined that the major
roles being performed by the \ac{DC} in a typical enterprise environment are
authentication and \ac{DNS}.  By use of native cmdlets, \ac{D-PLG} is capable
of generating four kinds of traffic designed to stress these services and
others: web, mail, file sharing, and \ac{MS} \ac{RDP}.  \ac{D-PLG} uses the
\ac{MS} Powershell environment to generate the traffic in an effort to make the
traffic as real as possible.  After building the tool, an experiment was
constructed and executed on a scale model of a production environment.  The
scaled simulation network was built using the recommendations of the \ac{MS}
community for sizing a \ac{DC}~\cite{mak12} and tested by running the
tool on five client machines against the \ac{DC} for five rounds of five
minutes.  The results of this test are shown in Figures~\ref{fig:authDCPPS},
\ref{fig:authClientPPS}, \ref{fig:authDCMetrics}.

\figAuthDCPPS{4in}
\figAuthClientPPS{4in}
\figAuthDCMetrics{4in}

\ac{D-PLG} makes use of client machines running a Windows operating system with
PowerShell version 4.0 or newer.  The controller asks each machine to generate
a configurable list of requests at evenly spaced intervals for a configurable
duration of time.  While this may not be realistic network traffic, it does
produce realistic load against a \ac{DC}.  Since \ac{D-PLG} depends on the use
of client machines, it is recommended that any load generation be conducted
during off-peak hours if spare client sized machines are not available.  It
should be noted however, that even with poorly resourced client machines (shown
in~\ref{tab:hyp1}), \ac{D-PLG} was able to generate fifteen thousand
authentication sessions over a five minute period; approximately 10
authentication sessions per machine, per second.  With modern workstations, the
impact on these client machines is negligible and they can be in use during
load generation.

Based on these results, and that a production \ac{DC} should be at
approximately 40\% \ac{CPU} utilization during peak utilization~\cite{mak12},
\ac{D-PLG} is capable of sufficiently loading the \ac{DC} over a sustained
period of time for the purposes of implementing the \ac{AFP} framework and is
used in this research.  Further, \ac{D-PLG} is capable of scaling to provide
load against higher capacity \ac{DC}s by using only a few client machines.
\ac{D-PLG} is available on
Github\footnote{https://github.com/paullj1/AFP-DC/tree/master/D-PLG} for others
to use.

\subsubsection{Events Manager} \label{sec:eventsManagerMgr}
This module is responsible for receiving and managing log messages and other
events that may be used to train the failure prediction algorithm.  Irrera, et
al.~\cite{irrera2015} use the \emph{Logman} tool for event management in their
original case study.  Since the experimental environment was modelled after the
Air Force enterprise environment, the \emph{Solar Winds} log forwarding tool is
used to perform the functions in this module as it is already present on many
of the Air Force \ac{DC}s.  The \ac{DC}s on the Sandbox and Target hypervisors
forward all events to the Ubuntu \ac{VM} with the \emph{rsyslog} server daemon
configured to receive all messages.  These messages are then processed and
added to a \ac{SQL} database for training and prediction.  

\subsubsection{Sandbox Management} \label{sec:sandboxMgr} 
The purpose of the sandbox management module is to supervise the virtual
cloning of the production system that is made when a new predictor is to be
trained.  As Irrera, et al.~\cite{irrera2015,irrera2013} point out, it is
typically inappropriate to inject faults and cause failures in production
systems, so a virtual clone must be created for that purpose.

The sandbox is managed manually using \ac{VM} snapshots.  After an initial
stable state was configured, snapshots of every component of the architecture
were taken so that they could be reset after iterations of the experiment.  It
is important to note here that because VMWare has documented \ac{API}s, in
future work, this function could be automated.

\subsection{Sandbox Hypervisor} \label{sec:sandbox}
The sandbox hypervisor hosts the virtual clone of the production environment
where faults will be injected and from which failure data will be collected.
Cloning the production environment ensures that the production system will not
be affected and service will be maintained during the training phase.  For the
purposes of this experiment, the sandbox is constructed on a single hypervisor
implemented as shown in Table~\ref{tab:hyp1}.  The following sections outline
each module within this module.

\subsubsection{Fault Injection} \label{sec:faultInjectionTool} 
This module is responsible for causing the target application to fail so that
labelled failure data can be generated in a short period of time.  As described
in Section~\ref{sec:faultInjectionMgr}, \ac{W-SWFIT} has been developed to
serve this purpose and implements the \ac{G-SWFIT} technique developed by
Duraes, et al.~\cite{gswfit} for fault injection.  The execution is controlled
by the Windows Server \ac{VM} on the Controller hypervisor through PowerShell
remote execution to reduce the interaction and potential to introduce bias into
the training data.  The tool allows us to inject a comprehensive list of faults
into the \ac{AD} Services processes and binary libraries which are mostly
contained within the `lsass.exe' process.  Since many of the critical functions
performed by the \ac{AD} Services processes are performed in one library called
`ntdsa.dll', it is the focus of fault injection.

This function is extended by this research to include failure as a result of
excessive load and failure as a result of a corrupt database.
Section~\ref{sec:extensions} covers these extensions in more depth.

\subsubsection{Monitoring} \label{sec:sandboxMonitoringTool} 
The purpose of this module is to capture some evidence or indication of pending
failure so that it may be used to train a prediction algorithm.  Irrera, et
al.~\cite{irrera2015} use the \emph{Logman} tool in their original study but
because the experimental infrastructure used in this research is modelled after
production Air Force networks, the \emph{Solar Winds} log forwarding tool is
used because it is already present in the Air Force architecture.  The tool is
a lightweight application that simply forwards Windows events to a syslog
server.

\subsubsection{Sandbox Workload}  \label{sec:sandboxWorkload} 
The sandbox workload module is likely the most critical module in the entire
framework.  Its purpose is to create realistic work for the target application
to do before faults are injected.  If the workload is not realistic, then the
failures that occur after fault injection will not be representative of real
failures and any data or indicators collected cannot be used to train an
effective prediction algorithm~\cite{cotroneo2012,kikuchi2014,irrera2015}.

Irrera, et al.~\cite{irrera2015} used a web traffic generator called TPC-W
installed on a single machine in their original study because their target was
a web server.  Because the \ac{DC} does not respond to web-requests and a tool
had not previously been written for this application, a tool was developed for
this research called \ac{D-PLG}. \ac{D-PLG} is a tool that generates
approximately ten full-stack authentication sessions requests per second in
order to sufficiently load the \ac{DC}.  \ac{D-PLG} is a distributed tool and
requires the use of client machines as a result.  This module is represented by
those client machines.  In this experiment, the client portion of \ac{D-PLG} is
installed on five client machines managed by the central workload manager as
discussed in Section~\ref{sec:workloadMgr}.

\subsection{Target Hypervisor} \label{sec:target}
The target hypervisor was constructed as a clone of the sandbox hypervisor
shown in Table~\ref{tab:hyp1}.  The following section outlines the monitoring
tool installed on the \ac{DC} on this hypervisor.  It should be noted here that
while the client machines were cloned as well for convenience, they were not
used in this experiment.

\subsubsection{Monitoring} \label{sec:targetMonitoringTool}
The monitoring module is exactly the same as the sandbox monitoring module and
for this experiment, the \emph{Solar Winds} syslog forwarding tool is used.  To
ensure that the messages that are sent are uniquely identified by the
controller, the hostname of the target machine must be different from the
hostname of the sandbox target machine.

\setcounter{secnumdepth}{3}

\section{Extenstions to the \ac{AFP}} \label{sec:extensions}
This section outlines a few extensions to the \ac{AFP} Framework specifically
with respect to the fault load.  Given that fault injection isn't always
considered representative~\cite{kikuchi2014}, this experiment explores three
other faults that may occur in a production environment:  an under-resourced
\ac{CPU}, not enough memory, and heap-space corruption.

Under some circumstances these faults may not be considered to lead to
realistic failure.  However, one reason an organization may wish to implement
the \ac{AFP} may be that monetary resources are not available to implement an
adequately redundant or sized \ac{DC}.  Consequently, load based failure may be a
realistic challenge faced by some organizations and knowing that such a failure
may occur might be valuable.  Furthermore, in some cases, third-party
applications or hardware drivers may be responsible for memory leaks or
accidental heap-space corruption.  Since the Windows operating system
implements shared library linking, hardware drivers that operate in kernel
space are able to overwrite areas of memory that are in use by critical system
processes~\cite{russinovich2009}.  The result is typically a system crash.

By adding these additional faults when generating failure data used to train a
prediction algorithm, the resulting algorithm will be able to predict a wider
range of realistic failures.  
