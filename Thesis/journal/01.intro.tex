\section{Introduction} \label{chapter1}
Computer systems are all around us.  Some of these systems play insignificant
roles in our lives while others are responsible for sustaining our lives.
Unfortunately, the software that controls these systems is written by humans
and consequently subject to human error.  As a result, these systems are prone
to failure with potentially catastrophic consequences.  

Being able to predict pending failure in those systems can offer tremendous,
and potentially life-saving applications.  While being able to accurately
predict failure has unfortunately not been proven possible, there has been work
over the past several decades attempting to make predictions about the failure
of machines through the use of machine learning
algorithms~\citep{salfnerSurvey}.  Unfortunately, much of this work has gone
unused~\citep{irrera2015}.  

In this case, failure is defined as the result of a software fault or
error~\citep{salfnerSurvey}.  There are a number of ways to reduce the number
of errors produced by a piece of software, but the software development
life-cycle is shrinking and less time and effort are being devoted to reducing
errors before deployment~\citep{schmidt2016}.  This leaves real-time error
prevention or handling.  In recent years, it seems the recommended solution to
this problem is to make massively redundant systems that can withstand
failure~\citep{bauer2012}.  This is an effective approach in many ways, but not
when funds are limited or system redundancy is limited by the enterprise
design.  Consequently, this research focuses on an area of reliable computing
called \ac{OFP}.  \ac{OFP} is the act of attempting to predict when failures
are likely so that they can be avoided~\citep{salfnerSurvey}.  

Due to the complex and manual task of training a prediction model, and since
failure is such a rare event, access to training data is limited.
\citet{irrera2015} presented the \ac{AFP} framework that automates the process
of dynamically generating failure data and using it to train a predictor after
an underlying system change.  Unfortunately, the types of failures simulated
within the framework were not completely representative of real
failures~\citep{kikuchi2014}.

This research presents an \ac{AFP} framework with a more representative fault
load including focused software fault injection, third party memory leaks,
third party \ac{CPU} over-utilization, and heap-space corruption.  The
implementation is then validated on a \ac{MS} Windows Server \ac{DC}, and on an
Apache web server.  Results identified that on the Windows Server 2008
operating system, software fault injection could not create a realistic failure
condition where more targetted fault loads could.  Furthermore, these failures
were identifiable by \ac{SVM} and boosted decision tree statistical learning
models with an average area under the \ac{ROC} curve of $0.98$.
