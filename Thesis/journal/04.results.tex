\section{Experimental Results and Analysis} \label{chapter4}
To test the extended \ac{AFP} framework, failure data were generated before a
series of major software updates using software fault injection,
under-resourced \ac{CPU}, under-resourced memory, and heap-space corruption on
two Windows Server 2008 machines: the \ac{DC} and the Apache web server.  The
failure data were used to train two statistical prediction models: an \ac{SVM}
classifier and a boosted decision tree.  Following the software updates, more
failure data were generated, and the old statistical models were used to
predict failure in the new data.  Finally, new statistical models were trained
using the new data.  To compare each fault load both before and after the
software updates, performance was measured using the \ac{AUC} and F-Measure.

In general, the \ac{AFP} framework works by virtually cloning the target
production system after it has determined that the system has changed.  In this
case, this determination is made after several important software updates.  The
framework then generates realistic work for the cloned service to perform,
which accelerates the activation of an injected fault.  When the cloned system
is sufficiently loaded, faults are injected until failure occurs.  Once failure
has occurred, the recorded data are used to train a statistical learning model.
The new model then replaces the existing model if it performs better.

Since log messages were used to train the statistical model, they needed to be
transformed to numerical data.  During execution, event messages were stored in
a flat file on the Ubuntu machine by the syslog server daemon in the
\emph{Snare}\footnote{\url{http://wiki.rsyslog.com/index.php/Snare\_and\_rsyslog}}
MSWinEventLog format.  The first element in each message is the timestamp and
host name of the sender, prepended by the syslog server daemon: \emph{May 8
14:31:52 dc.testnet.com}.  The remainder of the message contains tab-delimited
values; the keys (and consequent features) are shown in
Table~\ref{tab:message}.  Of these features, Criticality, EventLogSource,
EventID, SourceName, and CategoryString were selected for further encoding.

\tabMessage

Events were filtered by EventID, as is done by \citet{fulp2008}, to reduce the
noise generated by successful login attempts.  Log messages with IDs shown in
Table~\ref{tab:messageIDs} were filtered from the input.  

Next, to encode the time dimension and reduce the sequential message ordering
dependency, a sliding time window was created by counting each unique entry for
each feature within the data window ($\mathrm{\Delta t_d}$)
\citep{vaarandi2002}.  During this stage, the number of messages that were
reported in the data window was also recorded and used as a feature.

Finally, each time window preceding the failure within $\mathrm{\Delta t_l}$
was labelled failure prone \citep{irrera2015}.  This encoding enables the use
of classification algorithms in the training phase.  An example of the final
encoding is shown in Table~\ref{tab:window}.

\tabMessageIDs % Keep these together (footnote)
\footnotetext{\url{https://support.microsoft.com/en-us/kb/977519}}
\tabSlidingWindow

Feature reduction was performed for both learning algorithms on a sliding time
window \citep{fulp2008,irrera2013a,vaarandi2002}.  These transformed data were
then used to train a weighted \ac{SVM} and boosted decision-tree models using
cross-validation on $5$ recorded failure runs for each fault load for both
systems before and after the software updates.  These models were used because
of how well they tend to perform on unbalanced data.  Upon completion of the
data generation and model training, several performance measures were
calculated on the left-out test data.

This prediction method only provides a binary classification at a given time
that indicates whether a failure will occur within the fixed time window.
Other methods of prediction may offer more insight into when the failure may
occur, but they were not explored in this work.  Furthermore, given the
distinct differences between the training and execution phases, careful
consideration was given to real-time prediction.  During the Execution phase,
this same process occurs by maintaining a sliding time window by checking for
new log messages every second.

\subsection{\acrfull{MS} \acrfull{DC} Results}
The \ac{MS} \ac{DC} was configured in the virtual environment to host a
thirty-thousand-user database and perform \ac{DNS} and authentication for all
workstations.  The target of the fault injection was the \emph{lsass.exe}
process, specifically the \emph{ntdsa.dll} library.  This library is
responsible for processing authentication requests and handles interactions
with the user database.  For the \ac{DC}, failure was defined for this work as
a failure to authenticate using known good credentials.  When failure occurred,
on an average failure run, there were sixty-two thousand log messages, and
failure took approximately seven minutes to occur.  After translation, each run
contained approximately 672 observations. 

\subsubsection{Fault Injection}
Fault injection was effective at creating failures, but unfortunately, each
observed failure occurred immediately after introducing the fault.  Because
there was no delay between injection and failure ($\mathrm{\Delta t_l \approx
0}$), there did not exist any indicators of failure.  Consequently, machine
learning cannot help in this situation.  According to \citet{russinovich2009},
the \emph{lsass.exe} process, as well as other critical system processes, is at
the top of the structured exception-handling stack and does not handle
exceptions.  When faced with exceptions, the processes exit, and the system
reboots.

\subsubsection{Under-Resourced \ac{CPU}}
While this load resulted in authentication requests that took longer, it never
led to failure.  To test this load, the virtual domain controller resources
were reduced.  The \ac{CPU} went from a dual-core to a single virtual CPU, and
the memory was reduced from $2$ Gb to $512$ Mb.  This reduction was well
beneath the recommended capacity for a domain controller \citep{mak12}.  The
workload generator was then allowed to run against this configuration for seven
days.  For the duration of the test, the \ac{CPU} load was $100\%$, and the
physical memory was $90\%$ utilized on average.  While the service did
experience reduced response time, failure did not occur.

Another test was conducted with this load by allowing a third-party application
to slowly consume all \ac{CPU} time.  Much like the previous test, this test
never resulted in failure.  Consequently, learning was not attempted for this
load.

\subsubsection{Under-Resourced Memory}
The under-resourced memory load was the first to create observable indicators
of failure with any lead time.  This load produced the best-performing
predictors and the largest sliding time window for prediction of sixty seconds.
For this reason, this experiment explores the use of two machine learning
models: the weighted \ac{SVM} and boosted decision trees using the multinomial
distribution.  

\subsubsection{Weighted \ac{SVM}}
For this prediction method, the \emph{e1071} package in R was used to train an
\ac{SVM}.  The \emph{tune} function was used to conduct fivefold
cross-validation a total of $48$ times to select the best-performing parameters
(gamma, cost, and polynomial degree) using four kernels, four sliding
data/prediction windows, and three training/test data splits.  The
classification weights were set roughly equal to the proportion of
failure-prone to non-failure-prone data windows: $0.8$ for failure and $0.2$
for non-failure.

The best-performing parameters were the Radial kernel with $\gamma = 0.1$, $c =
1$, a time window of $60$ seconds, and the following data split: $4$ of the
observed failures were used for training, and the remainder were used for
testing.

The leave-one-out failure runs are sent to the predictor in temporal order over
the data windows to evaluate failure prediction.  The resulting
precision/recall and \ac{ROC} curves are shown in
Figure~\ref{fig:memLeakPreUpdateSVMPerf}.
Table~\ref{tab:memLeakPreUpdateSVMConfusionMatrix} shows the confusion matrix
on test data  created before software updates using the threshold that
corresponds to the highest F-Measure of $0.8739$. 

\figMemLeakPreUpdateSVMPerf
\tabMemLeakPreUpdateSVMConfusionMatrix

After the software update, the same model was used on a new set of generated
failures.  The old model did not accurately classify a single failure-prone
time window.  A new model was then trained with the newly generated failure
data.  Unfortunately, after this software update, with all other things held
constant, the weighted SVM model was unable to achieve the same level of
performance as before, resulting in a maximum F-Measure of $0.4380$.

\subsubsection{Boosted Decision Trees}
For this prediction model, the \emph{gbm} package in R was used to train a
boosted decision tree.  Cross-validation was used to select $\lambda = 0.03$,
the interaction depth of $4$, and the number of trees of $1000$.  The
multinomial distribution was used to perform classification.

The precision/recall and \ac{ROC} curves on a sixty-second data/prediction
window are shown in Figure~\ref{fig:memLeakCombinedBoostPerf}.  The confusion
matrix at the optimal threshold for the F-measure is shown in
Table~\ref{tab:memLeakPreUpdateBoostingConfusionMatrix}.

\figMemLeakCombinedBoostPerf
\tabMemLeakPreUpdateBoostingConfusionMatrix
% Confusion matrix on test data created before software updates on
% the threshold with the highest F-Measure (0.9917) using boosting.

After the software update, the same prediction model was used on a new set of
generated failures.  The precision/recall and \ac{ROC} curves on data generated
after the software update using the old model are shown in
Figure~\ref{fig:memLeakCombinedBoostPerf}.  The confusion matrix at the optimal
threshold for the F-measure is shown in
Table~\ref{tab:memLeakPreUpdateBoostingConfusionMatrix}

\tabMemLeakPostUpdateBoostingSameModelConfusionMatrix
% Post-update failure data confusion matrix on the threshold with the highest F-Measure
% (0.4691) using the model trained on failure data that were generated before the software
% update.

Finally, a new predictor was trained using more generated failures, as was done
before the update.  The precision/recall and \ac{ROC} curves on the left-out
test data are shown in Figure~\ref{fig:memLeakCombinedBoostPerf}, and the
confusion matrix at the optimal threshold for the F-measure is shown in
Table~\ref{tab:memLeakPostUpdateBoostingConfusionMatrix}.

\tabMemLeakPostUpdateBoostingConfusionMatrix
% Post-update failure data confusion matrix on threshold with the highest F-Measure
% (0.9355) using the model trained on failure data generated after the software update.

In summary, before the software update, the boosted decision tree, using test
data, achieved an \ac{AUC} of $0.9984$.  After the software update, the test
\ac{AUC} dropped to $0.4854$, but the model was retrained to achieve an
\ac{AUC} of $0.9801$.

\subsubsection{Heap-Space Corruption}
As with fault injection, heap-space corruption was able to produce failures,
but these failures were not preceded by any indicators.  To make the scenario
more realistic, the corruption was focused on the user database.  The user
database is incrementally cached as authentication requests are received
\citep{russinovich2009}.  To test this load, the \ac{AFP} execution phase was
run as usual.  After the workload generator reached a steady state, a single
user in the database on disk was corrupted, followed immediately by the same
user being corrupted in process memory.  If the disk was not corrupted along
with memory, the process would treat the corruption as a cache miss and
re-cache the user from the disk.  When both were corrupted simultaneously, the
process crashed and forced the system to reboot the very next time that user
requested authentication.  Unfortunately, exactly as with fault injection,
there were no preceding indicators of failure; thus, training a prediction
model was unsuccessful.

\subsection{Web Server}
To validate the approach and implementation of the \ac{AFP} framework in this
experiment, it was also tested against an Apache web server.  The underlying
system change in this experiment was simulated by upgrading Apache from version
\emph{2.2.31 x64} to version \emph{2.4.20 x64}.  The results for the web server
were almost identical to those for the \ac{DC} for each load.  In this case,
failure was defined as either a crash of the host process or a web page being
inaccessible.  The only predictable failure was in the case of the memory leak,
which resulted in the host process crashing.  The following sub-sections
outline specific results after testing each load.

\subsubsection{Fault Injection}
In the case of the web server, each library loaded by the Apache server process
\emph{httpd.exe} was targeted for fault injection.  In every case, faults were
injected until failure occurred.  Much like the \ac{DC}, for each failure
observed, no preceding indications of failure were visible in the log messages.

\subsubsection{Under-Resourced CPU}
Much like with the \ac{DC}, neither of the methods for creating this situation
resulted in failure.  The client machines did experience delayed responses, but
the server continued to run.

\subsubsection{Under-Resourced Memory}
As with the \ac{DC}, this was the only load that could be used to predict
failure given only reported errors.  However, machine learning was not
necessary given the low number of log messages produced.  Since Apache stores
access requests in a separate file, they were essentially pre-filtered.  Apache
also by default stores error messages in an external log.  There were no
messages reported in this file in any of the conducted failure runs.  The only
indicators that were produced were reported by Windows and recorded by the
rsyslog server.  An average of $15$ messages were reported during each round of
the execution phase, and the indicators of failure were easy to identify.  In
this case, simple rules could be used to predict failure in this process, so a
learning algorithm was not trained.  

After the Apache software update was applied, the indicators of failure did not
change and there were no additional messages reported in the separate error
log.  For this reason, the same updates were applied to the operating system as
for the \ac{DC} target.  After these updates, the indicators changed slightly,
but they were still very few and could be used to write a few simple rules.

These results do not diminish the utility of the \ac{AFP} framework.  Without
the framework, the indicators would still be unknown until after a failure.
Moreover, there would be no way to determine how long a set of rules would be
effective after being written.

\subsubsection{Heap-Space Corruption}
Heap-space corruption was tested against the Apache server by targeting the
actual web page stored in memory.  Much like what was done by the \ac{DC} with
users, this was treated as a cache miss and the content was retrieved from the
disk.  Again, to simulate a disk failure, this file was made inaccessible.  The
result was an immediate failure to serve the content.  As with the \ac{DC},
there were no preceding indications of failure.

\subsection{Summary}
In summary, the memory leak was the only load that was usable for training a
statistical model to predict failure based only on reported errors.  As
expected, the software update drastically reduced the effectiveness of a model
that was trained with failure data before the software update.  The boosted
decision tree was re-trainable after the software update, whereas the \ac{SVM}
was not.  This suggests that both models should be used to ensure the \ac{AFP}
framework maintains at least one useful predictor and is adaptable to
underlying system changes.

Perhaps most interestingly, fault injection, as was used in the original
\ac{AFP} framework implementation, had two extreme outcomes: 1) no failure or
2) immediate failure.  In the controlled virtual environment, failure was
predictable using polled system health information, but perhaps the indicators
used to predict the failure were not actual errors but rather the fault
injection tool itself injecting faults.  Since during the golden runs, the
fault injection tool never wrote to another processâ€™s memory, it is possible
that a predictor could identify these operations if system health statistics
are used as features instead of reported errors.  Furthermore, even only using
the Operator for Missing Function Call (OMFC), there were still thousands of
injection points in the Windows Server 2008 operating system.  Identifying the
handful that may activate in a realistic way without crashing the target
service immediately is not trivial.  Clearly, more work must be done to
validate using fault injection alone in the \ac{AFP} framework.

Ultimately, this work has shown that one minute of lead time is possible under
certain circumstances.  This amount of time is sufficient to perform a few
actions to mitigate failure.  First, the system could attempt to perform
software rejuvenation~\citep{candea2004microreboot}.  Failing that, it could
attempt to divert traffic to a redundant spare.
