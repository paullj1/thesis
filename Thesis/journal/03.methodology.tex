\section{Methodology} \label{chapter3}
The purpose of the \ac{AFP} framework is to automate the generation of
realistic labelled failure data for the purposes of automatically training a
failure prediction algorithm.  The framework breaks down into modules so that
it can be more easily adapted for different applications.  This section
presents three topics.  The first describes the process that the framework
executes in order to generate the labelled training data and train a failure
prediction algorithm.  The second describes each module of the extended
\ac{AFP} framework.  The final section details extensions to the \ac{AFP}
framework explored by this research.

This section outlines the implementation and extensions to the \ac{AFP}
framework \citep{irrera2015} as well as an experiment that was conducted to
validate those extensions and further generalize the framework.  The \ac{AFP}
framework was originally tested on a single system running an operating system
that has been deprecated.  Consequently, the results from the case study
conducted using the \ac{AFP} framework are limited in utility and require
generalization to be useful to the general community.

\subsection{Failure Data Generation} \label{sec:generation}
This work extends the \ac{AFP} framework \citep{irrera2015} by presenting
results after conducting another case study with an \ac{MS} Windows Server
acting as an \ac{AD} service with a more representative fault load as well as a
new implementation of the \ac{G-SWFIT} technique for the x86-64 architecture.

The case study was done using three new types of faults: third-party memory
leak, third-party \ac{CPU} overuse, and process memory corruption.  For
completeness, the standard \ac{G-SWFIT} technique was also used.  Another
important modification was made in the actual data collected.  The original
case study used status and machine state information polled every second.
\citet{salfnerSurvey} points out that this technique does not properly
distinguish between underlying errors and normal workload.  In this study,
reported errors are used instead.

Finally, findings are reported after implementing this framework using two
different statistical machine learning techniques on reported errors (log
messages): boosted decision trees and the weighted \ac{SVM}.  The weighted
\ac{SVM} was used because of it performs well on imbalanced data and it is
popular in the \ac{OFP} community \citep{salfnerSurvey}.  The boosted decision
tree was used because it is non-parametric, capable of classification, and
particularly suited for imbalanced data.  In both cases, feature reduction was
performed as is done by \citet{fulp2008}, on a sliding time window as is done
by \citet{irrera2013a,vaarandi2002}.

This section outlines the step-by-step procedure by which the extended \ac{AFP}
framework was evaluated to show how effective it is when used on Windows Server
deployments.  This is done by dividing the steps taken in the experiment into
the three major phases as defined by \citet{irrera2015}: preparation phase,
execution phase, and training phase.

\subsubsection{Preparation Phase}
In this phase the \ac{AFP} framework is prepared to run for the first time as
described by \citet{irrera2015}.  The \ac{CRISP-DM} \citep{crispdm} should be
applied to this situation when evaluating how to best apply the \ac{AFP} for a
particular target.  For the purposes of this research, the focus was on the
\ac{MS} Windows Directory Services and predicting failure in those services.
To demonstrate the efficacy of the \ac{AFP}, a predictor was evaluated before
and after a significant software update.  As a result, the most critical
preparation made in evaluating this framework was to hold back all software
updates on the target system prior to the first run of the execution phase.
The performance of various prediction techniques was evaluated both before and
after the Windows Update application was allowed to run.

\subsubsection{Execution Phase}
A general outline of this phase is shown in
Figure~\ref{fig:ExecutionPhaseHoriz}.  This phase is divided into three major
steps: data collection and failure prediction, event checking, and
training/update as described in this section.

\figExecutionPhaseHoriz{0.6\textwidth}

\paragraph{Data Collection and Failure Prediction}
In this phase, the system has a working predictor providing input to some sort
of decision system.  The system in this phase makes failure predictions about
the current state based on the last run of the training phase.  The output of
this process in this experiment was a warning message indicating a predicted
failure.

\paragraph{Event Checking}
Concurrent with the data collection and failure prediction sub-phase, the
\ac{AFP} framework continuously monitors events that may alter the underlying
system.  The output of each episode of this phase is a binary decision to
either begin the training phase, or not.  For this experiment, these events
were software updates and the training phase was manually triggered upon
completion of these updates.

\paragraph{Failure Predictor (Re-)Training and Update}
The purpose of this sub-phase is to initiate the training phase and compare its
results (a new predictor) with the currently employed predictor.  Should the
new predictor perform better, the old predictor is replaced by the new.  In
this experiment, this phase was accomplished manually.

\subsubsection{Training Phase}
The training phase is broken down into five major steps:  target replication,
data generation \& collection, dataset building, predictor training, and
analysis.  The general flow is shown in Figure~\ref{fig:TrainingPhase}.  Each
phase is outlined in the following sub-sections.

\figTrainingPhase{0.5\textwidth}

\paragraph{Target Replication}
During this phase a virtual clone of the target is made.  After the clone is
made, the fault injection and monitoring software is installed.  In this
experiment, the monitoring tool was the same as was already installed on the
production system so the extra step of installing the monitoring software was
unnecessary.

\paragraph{Data Generation \& Collection}
The purpose of this phase is to generate the data to train a new prediction
algorithm.  As a result, this sub-phase must be executed several times to
generate statistically meaningful datasets.  In this phase, the controller
triggers the cloned target startup.  Once startup is complete and the system
enters an idle state, the monitoring tool begins collecting data from the
target.  After monitoring has begun, the workload is started.  Once the
workload has entered a steady state, the fault load is started.  Finally, when
failure occurs, monitoring stops, the workload stops, and the system is
rebooted for the next run.  To generate golden data (or data with no failures
present to aid training), the first run omits the fault injection step.

The most critical part of this process is labelling the data when failure
occurs.  For the purposes of this experiment, failure was defined by the log
message ID $4625$: An account failed to log
on\footnote{\url{https://support.microsoft.com/en-us/kb/977519}}.  When this
occurred in conjunction with known valid credentials on an enabled account, the
preceding data window defined for the experiment was labelled as failure prone.
Additionally, the workload generator used in this research reported when
authentication failed and transmitted a syslog message to the controller.  

\paragraph{Dataset Building} \label{sec:dataset.building}
In this phase, the raw syslog messages are formatted and encoded to train the
prediction model.  The purpose of this phase is to prepare the raw messages to
be used as numeric inputs for the training phase.  During execution, event
messages were stored in a flat file on the Ubuntu machine by the syslog server
daemon in the
\emph{Snare}\footnote{\url{http://wiki.rsyslog.com/index.php/Snare\_and\_rsyslog}}
MSWinEventLog format.  The first element in each message is the time-stamp and
host name of the sender prepended by the syslog server daemon: \emph{May 8
14:31:52 dc.afnet.com}.  The remainder of the message contains tab delimited
values where the keys (and consequent features) are shown in
Table~\ref{tab:message}.  Of these features, Criticality, EventLogSource,
EventID, SourceName, and CategoryString were selected for further encoding.

\tabMessage

The raw messages were then encoded.  First, the events were filtered by EventID
as is done by \citet{fulp2008} to reduce the noise generated by successful
login attempts.  Log messages with IDs shown in Table~\ref{tab:messageIDs} were
filtered from the input.  

Next, to encode the time dimension and reduce the sequential message ordering
dependency, a sliding time window was created by counting each unique entry for
each feature within the data window ($\Delta t_d$) as is done by
\citet{vaarandi2002}.  During this stage, the number of messages that were
reported in the data window were also recorded and used as a feature.

Finally, each time window preceding the failure within $\Delta t$ was labelled
as failure prone as is done by \citet{irrera2015}.  This encoding enables the
use of classification algorithms in the training phase.  An example of the
final encoding is shown in Table~\ref{tab:window}.

\tabMessageIDs % Keep these together (footnote)
\footnotetext{\url{https://support.microsoft.com/en-us/kb/977519}}
\tabSlidingWindow

\paragraph{Predictor Training} \label{sec:predictor.training}
The purpose of this phase is to use the data generated by the forced failure of
the virtual clone to train a machine learning algorithm to classify a system as
failure prone or not.  

In this experiment, the execution phase was run $k$ times.  During this phase,
each of the $k$ datasets produced by the $k$ runs of the execution phase (each
containing a single failure), were used to train a statistical classification
model.  Each dataset was an $n \times p$ matrix where $n$ was the number of
sliding time windows and $p$ was the number of predictors present in the output
of the dataset building phase.  These $k$ datasets were used to conduct a $k -
1$-fold cross validation training and evaluation process where the first $k -
2$ datasets were used to train the statistical model.  The remaining set was
used to validate the trained model.  The data was then rotated and the process
was repeated $k - 1$ times.  Parameters for the classification model were
selected based on the output of this cross validation.  Finally, statistics and
performance on the final model's performance on the held out data set were
recorded.

\paragraph{Analysis}
During this phase, the precision, recall, f-measure, and area under the
\ac{ROC} curve are computed using the figures measured in the previous phase so
that the new predictor can be compared against the old.  If a new predictor
outperforms the old, the old is replaced with the new.  Upon completion of this
phase, control flow returns to the \emph{Event Checking} phase.  In this phase,
this analysis was done manually.

\subsection{Implementation of the \ac{AFP}} \label{sec:implementation}
\subsubsection{\ac{AFP} Framework Implementation}
This experiment replicated the experiment by \citet{irrera2015} with the
following modifications.  Most importantly, since the focus of this research is
on reported errors, log messages were used to train the predictor as is done in
many other recent approaches
\citep{domeniconi2002,fulp2008,salfner2007,watanabe2014}.  Instead of only
using fault injection to induce failure, three additional fault loads were
explored.  In addition to using the \ac{SVM} model, boosted decision trees were
evaluated.  Finally, in addition to the Apache web-server, the primary target
was the \ac{MS} Windows Server running \ac{AD} Domain Services.  The purpose of
Apache web server was to validate the approach and additional fault loads.  The
original \ac{AFP} architecture is shown in Figure~\ref{fig:annotatedAFP} with
the parts that were modified in this work highlighted.  

\subsubsection{\ac{AFP} Modules}
\citet{irrera2015} outline multiple modules into which they have broken the
\ac{AFP} framework for organizational purposes.  This research does not modify
these modules, instead, it takes a more granular approach and presents a
modified architecture and details each element of that architecture.

\figannotatedAFP

The following sections detail the virtual environment in which this
architecture was constructed.  For reference, this virtual environment was
hosted on two VMWare ESXi 5.5 hypervisors each with two 2.6 \ac{GHz} AMD
Opteron 4180 (6 cores each) \ac{CPU}s and 64 \ac{GB} memory.  The
specifications of the individual \ac{VM}s are shown in Tables~\ref{tab:hyp1},
and \ref{tab:hyp2}.

\tabHypervisorOne
\tabHypervisorTwo

\setcounter{secnumdepth}{5}

\subsubsection{Controller Hypervisor} \label{sec:controller} % 3.X.1
The controller responsibilities in this experiment were split between two
systems on a single hypervisor shown in Table~\ref{tab:hyp2}.  One system was
the \ac{MS} Windows Server responsible for workload management and fault
injection management.  The other system was an Ubuntu 14.04 server that
performed the failure prediction management and event management.  Each of
these functions is detailed in the following sections.

\paragraph{Failure Prediction} \label{sec:failurePrediction} % 3.X.1.1
The failure prediction module predicts failure using machine learning
algorithms trained using the labelled training data generated by the rest of
this framework.  This module is constantly either training a new predictor
because a software update occurred, or predicting failure based on log messages
and possibly other features produced by the production system.  In this
experiment, the statistical models were trained on input built as described in
Section~\ref{sec:dataset.building} using the popular statistical learning
software suite \emph{R}.

\paragraph{Fault Injection} \label{sec:faultInjectionMgr}
This module is responsible for managing the fault load used to create realistic
failure data.  \citet{irrera2015} use a single tool implementing the
\ac{G-SWFIT} for this module and pointed out that this module is the most
critical piece of the \ac{AFP} implementation.  \ac{G-SWFIT} was developed by
\citet{gswfit} to emulate software failures for the purposes of software
testing.  The method is widely implemented for use in software fault injection
both commercially and academically
\citep{cotroneo2012,irrera2014,natella2010,umadevi2015}. 

Unfortunately, previous \ac{G-SWFIT} tools were incapable of injecting faults
into elevated modern windows processes.  Older tools were written for Java or
x86 architectures \citep{gswfit,martins2002jaca,natella2010,sanches2011jswfit}.
For this reason, this work introduces a modernized fault injection tool capable
of injecting into x86-64 elevated system process (such as the `lsass.exe'
process).  This tool is called \ac{W-SWFIT} and its source code has been
published as open source on
Github\footnote{\url{https://github.com/paullj1/w-swfit/}} so that others may
use it for any of the reasons cited in the original \ac{G-SWFIT} paper
\citep{gswfit}.

Because of the concerns with fault
injection~\citep{cotroneo2012,kikuchi2014,natella2010}, this research generated
failure data using fault injection in conjunction with three new fault loads.
These new fault loads are covered in Section~\ref{sec:extensions}.

\paragraph{Workload Management} \label{sec:workloadMgr} 
The workload management module controls the generation of computational load by
directing the sandbox workload module to create realistic work for the
virtually cloned target to accomplish.  Without this module, it could take too
long for an injected fault to evolve into a failure.  Consider a missing
\emph{free} statement and the consequent memory leak.  A production target
server may have a large amount of available memory and the leak could be
relatively small.  To accelerate the possibility of failure occurring,
realistic load must be generated against the sandbox clone of the production
target.

In this experiment, the management and actual load generator roles have been
divided and a new tool has been developed: \ac{D-PLG} \citep{jordan2016}.
Realistic workload is critical in the implementation of the \ac{AFP} framework.
Consequently, \ac{D-PLG} has been designed and shown to provide a realistic and
sufficient workload for implementing the \ac{AFP} framework for a \ac{MS}
\ac{DC}.  The client portion of \ac{D-PLG} was used installed on five client
machines and used as the sandbox workload generator as discussed in
Section~\ref{sec:sandboxWorkload}.

\paragraph{Events Manager} \label{sec:eventsManagerMgr}
This module is responsible for receiving and managing log messages and other
events that may be used to train the failure prediction algorithm.
\citet{irrera2015} use the \ac{MS} \emph{Logman} tool from the remote
controller for event management in their original case study.  \emph{Logman}
was configured to poll $170$ system variables on the target machine once per
second.  

Since the focus of this research is on \emph{reported errors}, and the
experimental environment in this work was modelled after modern enterprise
environments where this sort of polling could produce too much data, this
experiment implemented an \emph{rsyslog} server daemon and the target was
configured to forward logs to it.  Moreover, because syslog is a standard
protocol, it is already in use in many enterprise networks today.  The messages
forwarded to the events manager were then processed and added to a \ac{SQL}
database for training and prediction.  

\paragraph{Sandbox Management} \label{sec:sandboxMgr} 
The purpose of the sandbox management module is to supervise the virtual
cloning of the production system that is made when a new predictor is to be
trained.  As \citet{irrera2013,irrera2015} point out, it is typically
inappropriate to inject faults and cause failures in production systems, so a
virtual clone must be created for that purpose.  Furthermore, the
virtualization of the target process has little affect on generated data
\citep{irrera2013}.

For this experiment, the sandbox was managed manually using \ac{VM} snapshots.
After an initial stable state was configured, snapshots of every component of
the architecture were taken so that they could be reset after iterations of the
experiment.  It is important to note here that because VMWare has documented
\ac{API}s, in future work, this function could be automated.

\subsubsection{Sandbox Hypervisor} \label{sec:sandbox}
The sandbox hypervisor hosts the virtual clone of the production environment
where faults are injected and from which failure data is collected.  Cloning
the production environment ensures that the production system is not be
affected and service are maintained during the training phase.  For the
purposes of this experiment, the sandbox was constructed on a single hypervisor
implemented as shown in Table~\ref{tab:hyp1}.  The following sections outline
each module within this module.

\paragraph{Fault Injection} \label{sec:faultInjectionTool} 
This module is responsible for causing the target application to fail so that
labelled failure data can be generated in a short period of time.  As described
in Section~\ref{sec:faultInjectionMgr}, \ac{W-SWFIT} has been developed to
serve this purpose and implements the \ac{G-SWFIT} technique developed by
\citet{gswfit} for fault injection.  The execution is controlled by the Windows
Server \ac{VM} on the `Controller' hypervisor through PowerShell remote
execution to reduce the interaction and potential to introduce bias into the
training data.  Since many of the critical functions performed by the \ac{AD}
services processes are performed in the
`ntdsa.dll'\footnote{\url{https://technet.microsoft.com/en-us/library/cc780455(v=ws.10).aspx}}
library loaded by the `lsass.exe' process, it was the focus of fault injection.

As mentioned, this work, introduces new fault loads.  These new loads are
discussed in Section~\ref{sec:extensions}.

\paragraph{Monitoring} \label{sec:sandboxMonitoringTool} 
The purpose of this module is to capture some evidence or indication of pending
failure at the target host level so that it may be used to train a statistical
prediction model.  In this experiment, syslog was used and while it is a
recognized standard, syslog messages are not produced natively in Windows.
Fortunately, several forwarding agents are available to translate and forward
native Windows log messages to a syslog server.  For this experiment, the
\emph{Solar Winds} syslog forwarding tool was used because of its popularity in
the security community and existing presence on many enterprise networks.  The
tool is a lightweight application that simply forwards Windows events to a
syslog server.

\paragraph{Sandbox Workload}  \label{sec:sandboxWorkload} 
The purpose of this module is to create realistic work for the target
application to do before faults are injected.  In this experiment, \ac{D-PLG}
was used as the work load generator for both the \ac{DC} and web requests.
This module was implemented using the client portion of \ac{D-PLG} installed on
five workstations and managed by the central workload manager as discussed in
Section~\ref{sec:workloadMgr}.

\subsubsection{Target Hypervisor} \label{sec:target}
The target hypervisor was constructed as a clone of the sandbox hypervisor
shown in Table~\ref{tab:hyp1}.  The following section outlines the monitoring
tool installed on both the \ac{DC} and web server on this hypervisor.

\paragraph{Monitoring} \label{sec:targetMonitoringTool}
The target monitoring module was implemented exactly as the sandbox monitoring
module was, using the \emph{Solar Winds} syslog forwarding tool.  The only
modification worth noting here is that to ensure the messages were uniquely
identifiable by the controller, the hostname of the target machine was changed
after cloning.

\setcounter{secnumdepth}{3}

\subsection{Extensions to the \ac{AFP}} \label{sec:extensions}
This section outlines the extensions to the \ac{AFP} framework explored by this
research.  Given that fault injection isn't always considered representative
\citep{kikuchi2014}, the next three sub-sections outline three addition fault
loads explored.  Next, an outline of the changes in how data was collected from
the target is presented.  Finally, this section concludes with a brief summary
of these extensions.

\subsubsection{Under-Resourced \ac{CPU}} \label{sec:extUnderResourcedCPU}
A \ac{CPU} may become under-resourced in a few ways.  The organization
implementing the target service may not accurately anticipate the amount of
load the service may experience.  Alternatively, a third-party application
installed on the same physical machine may inadvertently consume all \ac{CPU}
time.  The result in both of these situations is the target process gets
starved of \ac{CPU} time.

This condition was simulated in two ways to accurately capture both scenarios
outlined above.  First, by downsizing the number of virtual \ac{CPU}s available
to the target \ac{VM}.  Second, by introducing a third-party application that
ran at $100\%$ \ac{CPU}.

\subsubsection{Under-Resourced Memory} \label{sec:extUnderResourcedMem}
Available memory can be limited in a few ways.  As with the under-resourced
\ac{CPU}, the implementing organization may under estimate the amount of memory
that will be needed by a server to handle the required demand.  Additionally, a
third-party application could contain a memory leak.  In both cases, the target
application may not have enough memory to accomplish the work it has been
assigned.

To test this fault load, this experiment created both conditions outlined
above. First, as was done for the \ac{CPU}, the amount of memory available to
the target \ac{VM} was reduced.  Second, a third-party application with an
intentional memory leak was run on the target system.

\subsubsection{Heap Space Corruption} \label{sec:extHeapSpaceCorrupt}
Finally, heap-space corruption can happen in a production environment in a few
ways.  First, in the Windows operating system, device drivers share critical
kernel mode libraries and have elevated permissions \citep{russinovich2009}.
If a hardware device driver developer inadvertently writes to an area of memory
not allocated for his software, say by forgetting to dereference a pointer,
Windows may not warn him.  Consequently, he may corrupt the memory of another
process.

In this experiment, the focus of this fault load was on the user database.
First, users that had been cached by the \ac{DC} process were corrupted.  Next,
to simulate a disk failure, the same user was corrupted on disk.  To do this,
the \ac{W-SWFIT} code was modified to be able to search and write anywhere in a
processes memory.

\subsubsection{Reported Errors} \label{sec:extReportedErrors}
Finally, this research focusses on reported errors instead of system
information using the \emph{Logman} tool in the original study
\citep{irrera2015}.  As pointed out by \citet{salfnerSurvey}, a predictor only
given system information is not typically able to determine the difference
between a system that is going to fail and one that is perhaps under higher
than average load.  It may be able to pick up on \emph{undetected errors}, but
there is little to distinguish those from every day use.  Consider the \ac{DC}
and a memory leak situation.  According to \citet{russinovich2009}, the \ac{MS}
\ac{DC} will use as much memory as is available to cache user credentials.
This consumption of all available memory may appear very similar to a memory
leak if system information is all that is being recorded.

\subsubsection{Summary} \label{sec:extSum}
In summary, by adding these additional faults and considering reported errors
when generating failure data used to train a prediction algorithm, the
resulting algorithm will be able to predict a wider range of realistic
failures.  
