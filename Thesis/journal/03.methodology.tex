\section{Methodology} \label{chapter3}
The purpose of the \ac{AFP} framework is to automate the generation of
realistic labelled failure data for the purposes of automatically training a
failure prediction algorithm.  The framework breaks down into modules so that
it can be more easily adapted for different applications.  This chapter
presents three topics.  The first describes the process that the framework
executes in order to generate the labelled training data and train a failure
prediction algorithm.  The second describes each module of the extended
\ac{AFP} framework.  The final section details extensions to the \ac{AFP}
framework explored by this research.

This chapter outlines the implementation and extensions to the \ac{AFP}
framework~\cite{irrera2015} as well as an experiment that was conducted to
validate those extensions and further generalize the framework.  The \ac{AFP}
framework was originally tested on a single system running an operating system
that has been deprecated.  Consequently, the results from the case study
conducted using the \ac{AFP} framework are limited in utility and require
generalization to be useful to the general community.

\subsection{Failure Data Generation} \label{sec:generation}
This work extends the \ac{AFP} framework~\cite{irrera2015} by presenting
results after conducting another case study with an \ac{MS} Windows Server
acting as an \ac{AD} service with a more representative fault load as well as a
new implementation of the \ac{G-SWFIT} technique for the x86-64 architecture.

The case study was done using three new types of faults: third-party memory
leak, third-party \ac{CPU} hog, and process memory corruption.  For
completeness, the standard \ac{G-SWFIT} technique was also used.  Another
important modification was made in the actual data collected.  The original
case study used status and machine state information polled every second.
Salner et al.~\cite{salfnerSurvey} points out that this technique does not
properly distinguish between underlying errors and normal workload.  In this
case study, reported errors are used instead.

Finally, findings are reported after implementing this framework using two
different statistical machine learning techniques on reported errors (log
messages): boosted decision trees and the weighted \ac{SVM}.  The weighted
\ac{SVM} was used because of it performs well on imbalanced data and it is
popular in the \ac{OFP} community~\cite{salfnerSurvey}.  The boosted decision
tree was used because it is non-parametric, it is capable of classification,
and it is particularly suited for imbalanced data.  In both cases, feature
reduction was performed as is done by Fulp et al.~\cite{fulp2008}, on a sliding
time window as is done by Irrera, et al.~\cite{irrera2013a} and
Vaarandi~\cite{vaarandi2002}.

This section outlines the step-by-step procedure by which the extended \ac{AFP}
framework was evaluated to show how effective it is when used on Windows Server
deployments.  This is done by dividing the steps taken in the experiment into
the three major phases as defined in~\cite{irrera2015}: preparation phase,
execution phase, and training phase.

\subsubsection{Preparation Phase}
In this phase the \ac{AFP} framework is prepared to run for the first time as
described in~\cite{irrera2015}.  The \ac{CRISP-DM}~\cite{crispdm} should be
applied to this situation when evaluating how to best apply the \ac{AFP} for a
particular target.  For the purposes of this research, the focus was on the
\ac{MS} Windows Directory Services and predicting failure in those services.
To demonstrate the efficacy of the \ac{AFP}, a predictor was evaluated before
and after a significant software update.  As a result, the most critical
preparation made in evaluating this framework was to hold back all software
updates on the target system prior to the first run of the execution phase.
The performance of various prediction techniques was evaluated both before and
after the Windows Update application was allowed to run.  A complete list of
the updates installed is shown in Appendix~\ref{app:updates}.

This phase is essentially comprised of the manual act of implementing the
framework.  Each module of the implementation for this work is detailed in
Section~\ref{sec:implementation} and is therefore not discussed further here.  

\subsubsection{Execution Phase}
A general outline of this phase is shown in Figure~\ref{fig:ExecutionPhase}.
This phase is divided into three major steps: data collection and failure
prediction, event checking, and training/update as described in this section.

\figExecutionPhase{2.5in}

\paragraph{Data Collection and Failure Prediction}
In this phase, the system has a working predictor providing input to some sort
of decision system.  It should be noted here that this decision system does not
have to be automated.  The system in this phase makes failure predictions about
the current state based on the last run of the training phase.  This function
was not implemented in this research as it is application specific.  The output
of this process in this experiment was a warning message indicating a predicted
failure.

\paragraph{Event Checking}
Concurrent with the data collection and failure prediction sub-phase, the
\ac{AFP} framework continuously monitors events that may alter the underlying
system.  The output of each episode of this phase is a binary decision to
either begin the training phase, or not.  For this experiment, these events
were software updates and the training phase was manually triggered upon
completion of these updates.

\paragraph{Failure Predictor (Re-)Training and Update}
The purpose of this sub-phase is to initiate the training phase and compare its
results (a new predictor) with the currently employed predictor.  Should the
new predictor perform better, the old predictor is replaced by the new.  In
this experiment, this phase was accomplished manually.

\subsubsection{Training Phase}
The training phase is broken down into five major steps:  target replication,
data generation \& collection, dataset building, predictor training, and
analysis.  The general flow is shown in Figure~\ref{fig:TrainingPhase}.  Each
phase is outlined in the following sub-sections.

\figTrainingPhase{4in}

\paragraph{Target Replication}
During this phase a virtual clone of the target is made.  After the clone is
made, the fault injection and monitoring software is installed.  In this
experiment, the monitoring tool was the same as was already installed on the
production system so the extra step of installing the monitoring software was
unnecessary.

\paragraph{Data Generation \& Collection}
The purpose of this phase is to generate the data to train a new prediction
algorithm.  As a result, this sub-phase must be executed several times to
generate statistically meaningful datasets.  In this phase, the controller
triggers the cloned target startup.  Once startup is complete and the system
enters an idle state, the monitoring tool begins collecting data from the
target.  After monitoring has begun, the workload is started.  Once the
workload has entered a steady state, the fault load is started.  Finally, when
failure occurs, monitoring stops, the workload stops, and the system is
rebooted for the next run.  To generate golden data (or data with no failures
present to aid training), the first run omits the fault injection step.

The most critical part of this process is labelling the data when failure
occurs.  For the purposes of this experiment, failure was defined by the log
message ID $4625$: An account failed to log
on\footnote{\url{https://support.microsoft.com/en-us/kb/977519}}.  When this
occurred in conjunction with known valid credentials on an enabled account, the
preceding data window defined for the experiment was labelled as failure prone.
Additionally, the workload generator used in this research reported when
authentication failed and transmitted a syslog message to the controller.  

\paragraph{Dataset Building} \label{sec:dataset.building}
In this phase, the raw syslog messages are formatted and encoded to train the
prediction model.  The purpose of this phase is to prepare the raw messages to
be used as numeric inputs for the training phase.  Irrera, et
al.~\cite{irrera2015} loaded all data into a database for processing.  In this
work, the events were stored in a flat file on the Ubuntu machine by
the syslog server daemon.  An example of one of these messages is shown below:

\begin{lstlisting}
May  8 14:31:52 dc.afnet.com MSWinEventLog 5 Security 3 Sun May 08 14:31:50 2016 4672 Microsoft-Windows-Security-Auditing  N/A Audit Success dc.afnet.com 12548 Special privileges assigned to new logon.  Subject:  Security ID:  S-1-5-21-2379403389-181978965-2953995107-500  Account Name:  Administrator  Account Domain:  AFNET  Logon ID:  0x9beb4e7a  Privileges:  SeSecurityPrivilege    SeBackupPrivilege    SeRestorePrivilege    SeTakeOwnershipPrivilege    SeDebugPrivilege    SeSystemEnvironmentPrivilege    SeLoadDriverPrivilege    SeImpersonatePrivilege    SeEnableDelegationPrivilege
\end{lstlisting}

The messages were formatted using the
\emph{Snare}\footnote{\url{http://wiki.rsyslog.com/index.php/Snare\_and\_rsyslog}}
MSWinEventLog format which is generally divided into several categories.  The
first is the time-stamp and host name of the sender prepended by the syslog
server daemon: \emph{May 8 14:31:52 dc.afnet.com}.  The remainder of the
message contains tab delimited values where the keys (and consequent features)
are shown in Table~\ref{tab:message}.  Of these features, Criticality,
EventLogSource, EventID, SourceName, and CategoryString were selected for
further encoding.

\tabMessage

The raw messages were then encoded.  First, the events were filtered by EventID
as is done by Fulp et al.~\cite{fulp2008} to reduce the noise generated by
successful login attempts.  Log messages with IDs shown in
Table~\ref{tab:messageIDs} were filtered from the input.  

Next, to encode the time dimension and reduce the sequential message ordering
dependency, a sliding time window was created by counting each unique entry for
each feature within the data window ($\Delta t_d$) as is done by
Vaarandi~\cite{vaarandi2002}.  During this stage, the number of messages that
were reported in the data window were also recorded and used as a feature.

Finally, each time window preceding the failure within $\Delta t$ was labelled
as failure prone as is done by Irrera, et al.~\cite{irrera2015}.  This encoding
enables the use of classification algorithms in the training phase.  An example
of the final encoding is shown in Table~\ref{tab:window}.

\tabMessageIDs % Keep these together (footnote)
\footnotetext{\url{https://support.microsoft.com/en-us/kb/977519}}
\tabSlidingWindow

\paragraph{Predictor Training} \label{sec:predictor.training}
The purpose of this phase is to use the data generated by the forced failure of
the virtual clone to train a machine learning algorithm to classify a system as
failure prone or not.  

In this experiment, the execution phase was run $k$ times.  During this phase,
each of the $k$ datasets produced by the $k$ runs of the execution phase (each
containing a single failure), were used to train a statistical classification
model.  Each dataset was an $n \times p$ matrix where $n$ was the number of
sliding time windows and $p$ was the number of predictors present in the output
of the dataset building phase.  These $k$ datasets were used to conduct a $k -
1$-fold cross validation training and evaluation process where the first $k -
2$ datasets were used to train the statistical model.  The remaining set was
used to validate the trained model.  The data was then rotated and the process
was repeated $k - 1$ times.  Parameters for the classification model were
selected based on the output of this cross validation.  Finally, statistics and
performance was reported on the final model's performance on the held out data
set.

\paragraph{Analysis}
During this phase, the precision, recall, f-measure, and area under the
\ac{ROC} curve are computed using the figures measured in the previous phase so
that the new predictor can be compared against the old.  If a new predictor
outperforms the old, the old is replaced with the new.  Upon completion of this
phase, control flow returns to the \emph{Event Checking} phase.  In this phase,
this analysis was done manually.

\subsection{Implementation of the \ac{AFP}} \label{sec:implementation}
\subsubsection{\ac{AFP} Framework Implementation}
This experiment replicated the experiment in~\cite{irrera2015} with the
following modifications.  Most importantly, since the focus of this research is
on reported errors, log messages were used to train the predictor as is done in
many other recent
approaches~\cite{domeniconi2002,fulp2008,salfner2007,watanabe2014}.  Instead of
only using fault injection to induce failure, three additional fault loads were
explored.  In addition to using the \ac{SVM} model, boosted decision trees were
evaluated.  Finally, in addition to the Apache web-server, the primary target
was the \ac{MS} Windows Server running \ac{AD} Domain Services.  The purpose of
Apache web server was to validate the approach and additional fault loads.  The
original \ac{AFP} architecture is shown in Figure~\ref{fig:annotatedAFP} with
the parts that were modified in this work highlighted.  

\subsubsection{\ac{AFP} Modules}
Irrera, et al.~\cite{irrera2015} outline multiple modules into which they have
broken the \ac{AFP} framework for organizational purposes.  This research does
not modify these modules, instead, it takes a more granular approach and
presents a modified architecture and details each element of that architecture.

\figannotatedAFP  

The following sections detail the virtual environment in which this
architecture was constructed.  For reference, this virtual environment was
hosted on two VMWare ESXi 5.5 hypervisors each with two 2.6 \ac{GHz} AMD
Opteron 4180 (6 cores each) \ac{CPU}s and 64 \ac{GB} memory.  The
specifications of the individual \ac{VM}s are shown in Tables~\ref{tab:hyp1},
and \ref{tab:hyp2}.

\tabHypervisorOne
\tabHypervisorTwo

\setcounter{secnumdepth}{5}

\subsubsection{Controller Hypervisor} \label{sec:controller} % 3.X.1
The controller responsibilities in this experiment were split between two
systems on a single hypervisor shown in Table~\ref{tab:hyp2}.  One system was
the \ac{MS} Windows Server responsible for workload management and fault
injection management.  The other system was an Ubuntu 14.04 server that
performed the failure prediction management and event management.  Each of
these functions is detailed in the following sections.

\paragraph{Failure Prediction} \label{sec:failurePrediction} % 3.X.1.1
The failure prediction module predicts failure using machine learning
algorithms trained using the labelled training data generated by the rest of
this framework.  This module is constantly either training a new predictor
because a software update occurred, or predicting failure based on log messages
and possibly other features produced by the production system.

In the original case study, this module was implemented using an \ac{SVM}
prediction model using the \emph{libsvm} software library.  In this experiment,
the statistical models were trained on input built as described in
Section~\ref{sec:dataset.building} using the popular statistical learning
software suite \emph{R}.

\paragraph{Fault Injection} \label{sec:faultInjectionMgr}
This module is responsible for managing the fault load used to create realistic
failure data.  Irrera, et al.~\cite{irrera2015} use a single tool implementing
the \ac{G-SWFIT} for this module and pointed out that this module is the most
critical piece of the \ac{AFP} implementation.  \ac{G-SWFIT} was developed by
Duraes, et al.~\cite{gswfit} to emulate software failures for the purposes of
software testing.  The method is widely implemented for use in software fault
injection both commercially and
academically~\cite{cotroneo2012,irrera2014,natella2010,umadevi2015}.  

Recently, studies have questioned the representativeness of the failures
generated by \ac{G-SWFIT}~\cite{cotroneo2012,kikuchi2014}.  In each case, the
workload generated was critical in creating representative faults.  This
concern has been addressed in this research and is discussed in
Section~\ref{sec:workloadMgr}.

An additional concern regarding fault injection has been that some injected
faults may not elude modern software testing and as a result never actually
occur in production software~\cite{natella2010}.  The recommended remedy is to
conduct source code analysis to determine which pieces of code get executed
most frequently and avoid fault injection in those areas.  Unfortunately, the
target of this research is not an open source project and as a result, some of
the faults and resulting failures may never happen in a production environment.
Fortunately, the fault injection tool that has been developed for this research
automatically scans each library loaded by the target executable for fault
injection points and then is capable of evenly distributing the faults it does
inject.

Because of the concerns with fault injection, the experiment conducted in this
research tested three additional types of fault load to more exhaustively
represent realistic faults that may be encountered by a target process.  This
experiment trained a predictor using failures generated by third-party
applications purposefully written to slowly consume all available resources on
the target systems.  Specifically, the third-party application contains a
memory leak that slowly allocates all free system memory until the target
application crashes.  Next, failures were recorded as the result of a
third-party application consuming all \ac{CPU} time.  Source code for this
application is included in Appendix~\ref{app:resourceLeak}.  Finally, failure
was recorded after corrupting heap space in memory (versus program memory as
done by the \ac{G-SWFIT}).  This type of fault could be caused by privileged
third party applications such as hardware drivers inadvertently writing to the
target processes allocated memory.  Finally, for completeness, this experiment
uses a tool developed for this work that implements the \ac{G-SWFIT} technique.

This work introduces an x86-64 implementation of \ac{G-SWFIT} called
\ac{W-SWFIT}.  The source code for \ac{W-SWFIT} has been published as open
source on Github\footnote{\url{https://github.com/paullj1/w-swfit/}} so that
others may use it for any of the reasons cited in the original \ac{G-SWFIT}
paper~\cite{gswfit}.  For completeness, the source is also included in
Appendix~\ref{app:w-swfit}.  

For this research, the original plan was to use the same fault injection tool
used in the original case study by Irrera, et al.~\cite{irrera2015}.
Unfortunately, that tool, and all prior \ac{G-SWFIT} implementations were
incapable of injecting faults into x86-64 binary executables.  Further, many of
the commercial products that were evaluated for this research were incapable of
dealing with modern \ac{ASLR}.  As a result, \ac{W-SWFIT} was developed for
this research and is capable of injecting faults into all user and kernel mode
applications on modern \ac{MS} Windows operating systems.  

The key contributions of \ac{W-SWFIT} are \ac{ASLR} adaption, and the x86-64
translations that have been performed.  Further, as pointed out by Irrera, et
al.~\cite{irrera2013a}, prior implementations of the \ac{G-SWFIT} were not
capable of injecting faults into protected (kernel mode) processes.  Since the
focus of this research is on a protected system process, this capability was
critical, and as a result, \ac{W-SWFIT} was implemented in a way that made
protected process injection possible.  

\ac{G-SWFIT} works by scanning binary libraries already in memory for known
patterns (or operators).  These operators are then mutated to match compiled
errors that could have been made during development.  The errors targeted by
\ac{G-SWFIT} were discovered by analyzing open source project bug reports and
code repositories.  The errors were then classified based on the
\ac{ODC}~\cite{bridge1998} and are shown in Table~\ref{tab:faults}.  The point
of this mutation is that failure is ultimately the result of developer
error~\cite{irrera2015,salfnerSurvey}, and that fault injection accurately
simulates those errors~\cite{gswfit}.  Unfortunately, \ac{G-SWFIT} has only
previously been implemented for Java
applications~\cite{martins2002jaca,sanches2011jswfit}, and the IA32 instruction
set~\cite{gswfit,natella2010}.  Furthermore, the target applications in this
research are strictly x86-64 (also known as x64 or amd64) applications, and the
patterns identified previously are incompatible.  Consequently, to implement
the \ac{AFP} framework completely, a fault injection tool capable of mutating
x86-64 instructions in the same way was required.  \ac{W-SWFIT} implements two
of the operators from the original \ac{G-SWFIT} shown in
Table~\ref{tab:faults}: OMFC and OMLPA.  The translation of these operators was
not trivial given the complexity of the x86-64 architecture.  However, a simple
example of this translation is shown using the entry/exit points of a function
in Tables~\ref{tab:translationThirtyTwo}, and~\ref{tab:translationSixtyFour}.
The rest of the translations were done using the
\emph{Capstone}~\footnote{\url{http://www.capstone-engine.org}} library and can
be seen in source code for \ac{W-SWFIT}.

\tabFaults % Don't put before the definition of ODC... Super long acronym

\tabTranslationThirtyTwo
\tabTranslationSixtyFour

In summary, for the purposes of this research, fault injection was performed
four ways: software fault injection with \ac{W-SWFIT}, under-resourced memory,
under-resourced CPU, and heap space corruption.  Apart from \ac{W-SWFIT}, these
new fault loads are covered in more detail in Section~\ref{sec:extensions}.

\paragraph{Workload Management} \label{sec:workloadMgr} 
The workload management module controls the generation of computational load by
directing the sandbox workload module to create realistic work for the
virtually cloned target to accomplish.  Without this module, it could take too
long for an injected fault to evolve into a failure.  Consider a missing
\emph{free} statement and the consequent memory leak.  A production target
server may have a large amount of available memory and the leak could be
relatively small.  To accelerate the possibility of failure occurring,
realistic load must be generated against the sandbox clone of the production
target.

In the original \ac{AFP} case study, a Windows XP based web-server was the
target and the load generation management was collocated with the actual load
generator - a simple web request generator~\cite{irrera2015}.  In this
experiment, the management and actual load generator roles have been divided
and a new tool has been developed: \ac{D-PLG}.  The rest of this section
outlines \ac{D-PLG} and how it fulfills the workload and workload management
functions of the \ac{AFP} framework.

Realistic workload is critical in generating realistic failure and consequently
training a useful predictor.  Initial searches for a load generator suitable
for this research yielded a tool developed by \ac{MS} that initiated \ac{RDP}
connections to aid in sizing a terminal services
server\footnote{\url{http://www.microsoft.com/en-us/download/details.aspx?id=2218}}.
By executing an \ac{RDP} session, the authentication and \ac{DNS} functions of
the \ac{DC} would also be loaded.  Unfortunately, this tool is no longer
maintained and would not execute on the target
machine\footnote{\url{https://social.technet.microsoft.com/Forums/windowsserver/en-US/2f8fa5cf-3714-4eb3-a895-c30e2b26862d/debug-assertion-failed-sockcorecpp-line-623}}.
Further searches for tools that would sufficiently load the \ac{DC} did not
produce any results which led to the development of \ac{D-PLG}.

\ac{D-PLG} is a collection of remotely executed \ac{MS} PowerShell scripts
managed by a central script designed to generate realistic traffic that will
sufficiently load \ac{MS} enterprise services including a web server and
\ac{DC}.  Other network traffic generators typically work by replaying traffic
captured on a live network~\cite{jordan2016}.  This would likely work against
an unsecured web server, but unfortunately, due to the cryptographic nature of
authentication on a \ac{DC}, simply replaying traffic will not load such a
service since the timestamps and challenge responses will no longer be valid.
As a result, any replayed traffic will be dropped and ignored by a live
\ac{DC}.  \ac{D-PLG} solves this problem by making native authentication
requests by use of built-in PowerShell cmdlets (pronounced command-lets).  By
doing this, realistic authentication requests are sent to a \ac{DC} and are
actually processed.  Finally, the \ac{DNS} role can be stressed by sending the
authentication requests using domain names without allowing local caching.

By use of native cmdlets, \ac{D-PLG} is capable of generating four kinds of
traffic designed to stress the following services: authentication, web, mail,
file sharing, and \ac{MS} \ac{RDP}.  \ac{D-PLG} uses the \ac{MS} PowerShell
environment to generate the traffic in an effort to make the traffic as real as
possible.  After building the tool, an experiment was constructed and executed
on a scale model of a production environment.  The scaled simulation network
was built using the recommendations of the \ac{MS} community for sizing a
\ac{DC}~\cite{mak12} and tested by running the tool on five client machines
against the \ac{DC} for five rounds of five minutes.  The results of this test
are shown in Figures~\ref{fig:authDCPPS}, \ref{fig:authClientPPS},
\ref{fig:authDCMetrics}.

\figAuthDCPPS{4in}
\figAuthClientPPS{4in}
\figAuthDCMetrics{4in}

\ac{D-PLG} makes use of client machines running a Windows operating system with
PowerShell version $4.0$ or newer.  The controller asks each machine to
generate a configurable list of requests at evenly spaced intervals for a
configurable duration of time.  While this may not be realistic network
traffic, it does produce realistic load against a \ac{DC}.  Since \ac{D-PLG}
depends on the use of client machines, it is recommended that any load
generation be conducted during off-peak hours if spare client sized machines
are not available.  It should be noted however, that even with poorly resourced
client machines (shown in Table~\ref{tab:hyp1}), \ac{D-PLG} was able to
generate fifteen thousand authentication sessions over a five minute period;
approximately 10 authentication sessions per machine, per second.  With modern
workstations, the impact on these client machines is negligible and they can be
in use during load generation.

Based on these results, and that a production \ac{DC} should be at
approximately 40\% \ac{CPU} utilization during peak usage~\cite{mak12},
\ac{D-PLG} is capable of sufficiently loading the \ac{DC} over a sustained
period of time for the purposes of implementing the \ac{AFP} framework and was
used in this research.  Further, \ac{D-PLG} is capable of scaling to provide
load against higher capacity \ac{DC}s by using only a few client machines.
\ac{D-PLG} is available on
Github\footnote{https://github.com/paullj1/AFP-DC/tree/master/D-PLG} for others
to use.

In this experiment, \ac{D-PLG} was used as the central workload manager.
Furthermore, the client portion of \ac{D-PLG} was used installed on five client
machines and used as the sandbox workload generator as discussed in
Section~\ref{sec:sandboxWorkload}.

\paragraph{Events Manager} \label{sec:eventsManagerMgr}
This module is responsible for receiving and managing log messages and other
events that may be used to train the failure prediction algorithm.  Irrera, et
al.~\cite{irrera2015} use the \ac{MS} \emph{Logman} tool from the remote
controller for event management in their original case study.  \emph{Logman}
was configured to poll $170$ system variables on the target machine once per
second.  

Since the focus of this research is on \emph{reported errors}, and the
experimental environment in this work was modelled after modern enterprise
environments where this sort of polling could produce too much data, this
experiment implemented an \emph{rsyslog} server daemon and the target was
configured to forward logs to it.  Moreover, because syslog is a standard
protocol, it is already in use in many enterprise networks today.  The messages
forwarded to the events manager were then processed and added to a \ac{SQL}
database for training and prediction.  

\paragraph{Sandbox Management} \label{sec:sandboxMgr} 
The purpose of the sandbox management module is to supervise the virtual
cloning of the production system that is made when a new predictor is to be
trained.  As Irrera, et al.~\cite{irrera2013,irrera2015} point out, it is
typically inappropriate to inject faults and cause failures in production
systems, so a virtual clone must be created for that purpose.  Furthermore, the
virtualization of the target process has little affect on generated
data~\cite{irrera2013}.

For this experiment, the sandbox was managed manually using \ac{VM} snapshots.
After an initial stable state was configured, snapshots of every component of
the architecture were taken so that they could be reset after iterations of the
experiment.  It is important to note here that because VMWare has documented
\ac{API}s, in future work, this function could be automated.

\subsubsection{Sandbox Hypervisor} \label{sec:sandbox}
The sandbox hypervisor hosts the virtual clone of the production environment
where faults are injected and from which failure data is collected.  Cloning
the production environment ensures that the production system is not be
affected and service are maintained during the training phase.  For the
purposes of this experiment, the sandbox was constructed on a single hypervisor
implemented as shown in Table~\ref{tab:hyp1}.  The following sections outline
each module within this module.

\paragraph{Fault Injection} \label{sec:faultInjectionTool} 
This module is responsible for causing the target application to fail so that
labelled failure data can be generated in a short period of time.  As described
in Section~\ref{sec:faultInjectionMgr}, \ac{W-SWFIT} has been developed to
serve this purpose and implements the \ac{G-SWFIT} technique developed by
Duraes, et al.~\cite{gswfit} for fault injection.  The execution is controlled
by the Windows Server \ac{VM} on the `Controller' hypervisor through PowerShell
remote execution to reduce the interaction and potential to introduce bias into
the training data.  The tool allowed us to inject a comprehensive list of faults
into the \ac{AD} services processes and binary libraries which are mostly
contained within the `lsass.exe' process.  Since many of the critical functions
performed by the \ac{AD} services processes are performed in one library called
`ntdsa.dll'\footnote{\url{https://technet.microsoft.com/en-us/library/cc780455(v=ws.10).aspx}},
it was the focus of fault injection.

This function was extended by this research to include failure as a result of
third-party memory and \ac{CPU} leaks, and memory corruption.
Section~\ref{sec:extensions} covers these extensions in more depth.

\paragraph{Monitoring} \label{sec:sandboxMonitoringTool} 
The purpose of this module is to capture some evidence or indication of pending
failure at the target host level so that it may be used to train a statistical
prediction model.  Since Irrera, et al.~\cite{irrera2015} use the \emph{Logman}
remotely, no additional software was needed on the host.  In this experiment,
syslog was used and while it is a recognized standard, syslog messages are not
produced natively in Windows.  Fortunately, several forwarding agents are
available to translate and forward native Windows log messages to a syslog
server.  For this experiment, the \emph{Solar Winds} syslog forwarding tool was
used because of its popularity in the security community and existing presence
on many enterprise networks.  The tool is a lightweight application that simply
forwards Windows events to a syslog server.

\paragraph{Sandbox Workload}  \label{sec:sandboxWorkload} 
The purpose of this module is to create realistic work for the target
application to do before faults are injected.  If the workload is not
realistic, then the failures that occur after fault injection will not be
representative of real failures and any data or indicators collected cannot be
used to train an effective prediction
algorithm~\cite{cotroneo2012,irrera2015,kikuchi2014}.

Irrera, et al.~\cite{irrera2015} used a web traffic generator called TPC-W
installed on a single machine in their original study because their target was
a web server.  This would be the ideal tool for the validation test on the
Apache web server in this experiment but unfortunately, this tool has been
deprecated and no substitute has been
written~\footnote{\url{http://www.tpc.org/tpcw/}}.  As a result, \ac{D-PLG} was
used as the work load generator for both the \ac{DC} and web requests.

\ac{D-PLG} is a distributed tool and requires the use of client machines.  This
module is represented by those client machines.  In this experiment, the client
portion of \ac{D-PLG} was installed on five client machines managed by the
central workload manager as discussed in Section~\ref{sec:workloadMgr}.

\subsubsection{Target Hypervisor} \label{sec:target}
The target hypervisor was constructed as a clone of the sandbox hypervisor
shown in Table~\ref{tab:hyp1}.  The following section outlines the monitoring
tool installed on both the \ac{DC} and web server on this hypervisor.

\paragraph{Monitoring} \label{sec:targetMonitoringTool}
The monitoring module is exactly the same as the sandbox monitoring module and
for this experiment, the \emph{Solar Winds} syslog forwarding tool was used.
The only modification worth noting here is that to ensure that the messages
sent were uniquely identified by the controller, the hostname of the target
machine must be different from the hostname of the sandbox target machine.

\setcounter{secnumdepth}{3}

\subsection{Extensions to the \ac{AFP}} \label{sec:extensions}
This section outlines the extensions to the \ac{AFP} framework explored by this
research.  Given that fault injection isn't always considered
representative~\cite{kikuchi2014}, the next three sub-sections outline three
addition fault loads explored.  Next, an outline of the changes in how data was
collected from the target is presented.  Finally, this chapter concludes with a 
brief summary of these extensions.

\subsubsection{Under-Resourced \ac{CPU}} \label{sec:extUnderResourcedCPU}
A \ac{CPU} may become under-resourced in a few ways.  The organization
implementing the target service may not accurately anticipate the amount of
load the service may experience.  Alternatively, a third-party application
installed on the same physical machine may inadvertently consume all \ac{CPU}
time.  The result in both of these situations is the target process gets
starved of \ac{CPU} time.

This condition was simulated in two ways to accurately capture both scenarios
outlined above.  First, by downsizing the number of virtual \ac{CPU}s available
to the target \ac{VM}.  Second, by introducing a third-party application that
ran at $100\%$ \ac{CPU}.  The source code for this application is shown in
Appendix~\ref{app:resourceLeak}.

\subsubsection{Under-Resourced Memory} \label{sec:extUnderResourcedMem}
Available memory can be limited in a few ways.  As with the under-resourced
\ac{CPU}, the implementing organization may under estimate the amount of memory
that will be needed by a server to handle the required demand.  Additionally, a
third-party application could contain a memory leak.  In both cases, the target
application may not have enough memory to accomplish the work it has been
assigned.

To test this fault load, this experiment created both conditions outlined
above. First, as was done for the \ac{CPU}, the amount of memory available to
the target \ac{VM} was reduced.  Second, a third-party application with an
intentional memory leak was run on the target system.  The source code for this
application is also shown in Appendix~\ref{app:resourceLeak}.

\subsubsection{Heap Space Corruption} \label{sec:extHeapSpaceCorrupt}
Finally, heap-space corruption can happen in a production environment in a few
ways.  First, in the Windows operating system, device drivers share critical
kernel mode libraries and have elevated permissions~\cite{russinovich2009}.  If
a hardware device driver developer inadvertently writes to an area of memory
not allocated for his software, say by forgetting to dereference a pointer,
Windows may not warn him.  Consequently, he may corrupt the memory of another
process.

In this experiment, the focus of this fault load was on the user database.
First, users that had been cached by the \ac{DC} process were corrupted.  Next,
to simulate a disk failure, the same user was corrupted on disk.  To do this,
the \ac{W-SWFIT} code was modified to be able to search and write anywhere in a
processes memory.  This code is shown in Appendix~\ref{app:w-swfit}.

\subsubsection{Reported Errors} \label{sec:extReportedErrors}
Finally, this research focusses on reported errors instead of system
information using the \emph{Logman} tool in the original
study~\cite{irrera2015}.  As pointed out by Salfner, et
al.~\cite{salfnerSurvey}, a predictor only given system information is not
typically able to determine the difference between a system that is going to
fail and one that is perhaps under higher than average load.  It may be able to
pick up on \emph{undetected errors}, but there is little to distinguish those
from every day use.  Consider the \ac{DC} and a memory leak situation.
According to Russinovich, et al.~\cite{russinovich2009}, the \ac{MS} \ac{DC}
will use as much memory as is available to cache user credentials.  This
consumption of all available memory may appear very similar to a memory leak if
system information is all that is being recorded.

\subsubsection{Summary} \label{sec:extSum}
In summary, by adding these additional faults and considering reported errors
when generating failure data used to train a prediction algorithm, the
resulting algorithm will be able to predict a wider range of realistic
failures.  
