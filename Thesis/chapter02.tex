\chapter{Overview of \ac{OFP}} \label{chapter2}
This chapter reviews current research regarding \ac{OFP} and its many
approaches to build a foundation for this research.  Further, the taxonomy of
approaches developed by Salfner, et al.~\cite{salfnerSurvey}, is updated by
classifying approaches since its publication and creating a new sub-category.

The rest of this chapter is organized as follows.  In Section~\ref{background},
a brief background on the topic of \ac{OFP} is given including definitions,
terminology, and measures of performance used by the community.  In
Section~\ref{approaches}, the approaches relevant to this research are
presented followed by a brief summary in Section~\ref{summary}.

\section{Background} \label{background}
In 2010, Salfner, et al.~\cite{salfnerSurvey} published a survey paper that
provides a comprehensive summary of the state of the art on the topic of
\ac{OFP}.  In addition to the review of the literature up to the point of
publication, they provide a summary of definitions and measures of performance
commonly used in the community for couching the \ac{OFP} discussion.

\subsection{Definitions} \label{definitions}
\subsubsection{\ac{PFM}} \label{pfm}
Salfner, et al.~\cite{salfnerSurvey} define \ac{PFM} as the process by which
faults are handled in a proactive way, analogous with \emph{fault tolerance}
and basically consisting of four steps: \ac{OFP}, diagnosis, action scheduling,
and action execution as shown in Figure~\ref{fig:proactiveFaultManagement}.
The final three stages of \ac{PFM} define how much lead time is required to
avoid a failure when predicted during \ac{OFP}.  \emph{Lead time} is defined as
the time between when failure is predicted and when that failure will occur.
Lead time is one of the most critical elements of a failure prediction
approach.

\figproactiveFaultManagement{0.8\textwidth}

\ac{OFP} is defined as the first step in \ac{PFM} shown in
Figure~\ref{fig:proactiveFaultManagement}.  \ac{OFP} is the act of analyzing
the running state of a system in order to predict failure in that system. Once
failure has been predicted, a fault tolerant system must determine what will
cause the failure.  This stage is called the \emph{diagnosis} stage or
``root-cause analysis'' stage.  During the \emph{diagnosis} stage, the analysis
must be conducted so that a system knows which remediation actions are
possible.  After it is determined what will cause a failure, a fault tolerant
system must schedule a remediation action that is either performed by an
operator or done automatically.  This stage is known as the \emph{action
scheduling} stage and normally takes as input the cost of performing an action,
confidence in prediction, effectiveness/complexity of remedy action and makes a
decision about what action to perform based on that input.  In some cases a
remedy action can be so simple that even if the confidence in the prediction is
low, the action can still be performed with little impact on the overall system
and its users.  A thorough analysis of the trade-off between cost of avoidance
and confidence in prediction and the associated benefits is described
in~\cite{candea2004microreboot}.  Finally, in order to avoid failure, a system
must execute the scheduled remediation action or let an operator know which
actions can be taken in a stage called \emph{action execution}.

\subsubsection{Faults, Errors, Symptoms, and Failures}
This research uses the definitions from~\cite{avivzienis2004basic} as
interpreted and extended in~\cite{salfnerSurvey} for the following terms:
failure; error (detected versus undetected); fault; and symptom.

\emph{Failure} is an event that occurs when the delivered service deviates from
correct service.  In other words, things can go wrong internally; as long as
the output of a system is what is expected, failure has not occurred.  

An \emph{error} is the part of the total state of the system that may lead to
its subsequent service failure.  \emph{Errors} are characterized as the point
when things go wrong~\cite{salfnerSurvey}.  Fault tolerant systems can handle
errors without necessarily evolving into failure.  There are two kinds of
errors.  First, a \emph{detected error} is an error that is reported to a
logging service.  In other words, if it can be seen in a log then it is a
detected error.  Second, \emph{undetected errors} are errors that have not been
identified by an error detector.  Undetected errors are things like memory
leaks.  The error exists, but as long as there is usable memory, it is not
likely to be reported to a logging service.  Once the system runs out of usable
memory, undetected errors will likely appear in logs and become a detected
errors.  A \emph{fault} is the hypothesized root cause of an error.  Faults can
remain dormant for some time before manifesting themselves and causing an
incorrect system state.  In the memory leak example, the missing \emph{free}
statement in the source code would be the fault.  

A \emph{symptom} is an out-of-norm behavior of a system's parameters caused by
errors, whether detected or undetected.  In the memory leak example, a possible
symptom of the error might be delayed response times due to sluggish
performance of the overall system.

\figfailureFlowDiagram{\textwidth}

Figure~\ref{fig:failureFlowDiagram} illustrates how a software fault can evolve
into a failure.  Faults, errors, symptoms, and failures can be further
categorized by how they are detected also shown in
Figure~\ref{fig:failureFlowDiagram}.  Salfner, et al.~\cite{salfnerSurvey}
introduces a taxonomy of \ac{OFP} approaches and classifies failure prediction
approaches by the stage at which a fault is detected as it evolves into a
failure: auditing, reporting, monitoring, and tracking.  Testing is left out
because it does not help detect faults in an online sense.  

\figonlinePrediction{0.8\textwidth}

Figure~\ref{fig:onlinePrediction} demonstrates the timeline associated with
\ac{OFP}.  The parameters used by the community to define a predictor are as
follows:
\begin{itemize}
	\item{Present Time: $t$}
  \item{Lead Time: $\Delta t_{l}$, is the total time at which a predictor makes
  an assessment about the current state.}
  \item{Data Window: $\Delta t_{d}$, represents the time from which data is
  used for a predictor uses to make its assessment.}
  \item{Minimal Warning Time: $\Delta t_{w}$, is the amount of time required to
  avoid a failure if one is predicted.}
  \item{Prediction Period: $\Delta t_{p}$, is the time for which a prediction
  is valid.  As $\Delta t_{p} \rightarrow \infty$, the accuracy of the
  predictor approaches 100\% because every system will eventually fail.  As
  this happens, the usefulness of a predictor is diminished.}
\end{itemize}

As the above parameters are adjusted, predictors can become more or less
useful.  For example, it is clear that as a predictor looks further into the
future potentially increasing \emph{lead time}, confidence in its prediction is
likely to be reduced.  On the other hand, if \emph{lead time} is too small,
there will likely not be enough time to effectively take remediation action.
In general, \ac{OFP} approaches seek to find a balance between the parameters,
within an acceptable bound depending on application, to achieve the best
possible performance.

\section{Approaches to \ac{OFP}} \label{approaches}
\subsection{\ac{OFP} Taxonomy}
The taxonomy by Salfner, et al.~\cite{salfnerSurvey} classifies many of the
\ac{OFP} approaches in the literature into four major categories.  These four
major categories are defined by the four techniques used to detect faults in
real-time: auditing, monitoring, reporting, and tracking as illustrated in
Figure~\ref{fig:failureFlowDiagram}.  The taxonomy is shown in
Figure~\ref{fig:OFPTaxonomy}.

\figOFPTaxonomy{0.8\textwidth}

Since this research focusses on real-time \emph{data-driven} device failure
prediction approaches, our focus is on the \emph{reporting} category of
Salfner's taxonomy.  The \emph{reporting} category organizes failure prediction
techniques that attempt to classify a state as failure prone based on reported
errors.  Salfner, et al.~\cite{salfnerSurvey} further organize the reporting
category into five sub-categories: rule-based systems; co-occurrence; pattern
recognition; statistical tests; and classifiers.

\emph{Rule-Based Systems} attempt to classify a system as being failure-prone
or not based a set of conditions met by reported errors.  Since modern systems
are far too complex to build a set of conditions manually, these approaches
seek to find automated ways of identifying these conditions in training data.
\emph{Co-occurrence} predictors generate failure predictions based on the
reported errors that occur either spatially or temporally close together.
\emph{Pattern Recognition} predictors attempt to classify patterns of reported
errors as failure prone.  \emph{Statistical Tests} attempt to classify a system
as failure-prone based on statistical analysis of historical data.  For
example, if a system is generating a much larger volume of error reports than
it typically does, it may be a sign of pending failure.  \emph{Classifiers}
assign labels to given sets of error reports in training data and then make
failure predictions based on observed labels in real-time data.  

This research focusses on pattern recognition OFP approaches, which are shown
in Figure~\ref{fig:patternRecognition}.  Strategies employed in the other
sub-categories are closely related and thus are also explored in this research.

\figpatternRecognition{\textwidth}

\subsection{Data-Driven \ac{OFP}}
% The survey published by Salfner et al. covered approaches in every sub-category
% of the \emph{reporting} category.  Since the publication of the survey, we
% found approaches in two of the subcategories, \emph{pattern recognition} and
% \emph{classifiers}.  We therefore only cover the approaches in those
% sub-categories of the reporting category here.  We found some of the approaches
% published since Salfner's survey to be difficult to classify because they
% employ aspects of the other sub-categories in the \emph{reporting} category.
% More specifically, many of the modern techniques seem to be a blend between the
% two sub-categories \emph{pattern recognition} and \emph{classifiers}.  We
% believe these categories have been blended because these approaches seem to
% follow general human intuition when looking for software failures.  In other
% words, we have found that cyber operators tend to look for patterns in reported
% errors and then classify a situation based on those patterns.  We therefore
% categorize these approaches as \emph{hybrid} approaches.

\subsubsection{Pattern Recognition}
Salfner, et al.~\cite{salfner2006} proposed an approach to predicting failures
by learning patterns of similar events using a semi-Markov chain model.
The model learned patterns of error reports that led to failure by mapping the
reported errors to the states in the Markov chain and predicted the probability
of the transition to a failure-prone state.  They tested the model using
performance failures of a telecommunication system and reported a precision of
0.8, recall of 0.923, and an F-measure of 0.8571, which drastically
outperformed the models to which it was compared.

Given the results, the semi-Markov Chain model is compelling however, it
depends on the sequence of reported errors to remain constant in order to be
effective.  Today, most software is multi-threaded or distributed so there is
no guarantee that the sequence of reported errors will remain constant.
Further, the authors reported that this approach did not scale well as the
complexity of the reported errors grew.

In 2007, Salfner, et al. extended their previous work in~\cite{salfner2006}
using semi-Markov models~\cite{salfner2007}.  They generalized the Hidden
Semi-Markov process for a continuous-time model and called it the \ac{GHSMM}.
By making this generalization, the model was able to effectively predict the
sequence of similar events (or in this case, errors) in the continuous time
domain.  The authors then tested the model and training algorithm using
telecommunication performance failure data and compared it to three other
approaches.  While this \ac{GHSMM} model did not perform as well as their
previous work, it did outperform the models to which it was compared and more
importantly did not depend on the sequence of reported errors.  In other words,
this new \ac{GHSMM} model predicted failure for permutations of a known
failure-prone sequence making it more suited for a distributed or parallel
system.

The \ac{GHSMM} approach has been well received by the community, although
appears to be limited in use to a single system.  Unfortunately, this approach
as well as its predecessor, does not scale well and does not adapt to changes
to the underlying system without retraining.

\subsubsection{Classifiers}
Domeniconi, et al.~\cite{domeniconi2002} published a technique that used
\ac{SVM} to classify the present state as either failure prone or not based on
a window of error reports as an input vector.  As Salfner points out
in~\cite{salfnerSurvey}, this \ac{SVM} approach would not be useful without
some sort of transformation of the input vector since the exact same sequence
of error messages, rotated by one message, would not be classified as similar.
To solve this permutation challenge, the authors in~\cite{domeniconi2002} used
singular value decomposition to isolate the sequence of error reports that led
to a failure.

This \ac{SVM} approach used training data from a production computer
environment with 750 hosts over a period of 30 days.  The types of failures the
system was trying to detect was the inability to route to a web-page and an
arbitrary node being down.  Many approaches involving \ac{SVM}s have been
explored since and seem to be popular in the community~\cite{fronza2013,
fulp2008, murray2005, domeniconi2002, irrera2015}.

\subsubsection{Hybrid Approaches}
\emph{Fujitsu Labs} has published several papers on an approach for predicting
failure in a cloud-computing
environment~\cite{sonoda2012,watanabe2012,watanabe2014}.  Watanabe, et
al.~\cite{watanabe2014, watanabe2012} report on findings after applying a
Bayesian learning approach to detect patterns in similar log messages.  Their
approach abstracts the log messages by breaking them down into single words and
categorizing them based on the number of identical words between multiple
messages.  This hybrid approach removes the details from the messages, like
node identifier, and \ac{IP} address while retaining meaning of the log
message.

Watanabe et al.'s~\cite{watanabe2014} hybrid approach attempts to solve the
problem of underlying system changes by learning new patterns of messages in
real-time.  As new messages come in, the model actively updates the probability
of failure by Bayesian inference based on the number of messages of a certain
type that have occurred within a certain time window.  The authors claim that
their approach solves three problems: 1)  The model is not dependent upon a
certain lexicon used to report errors to handle different messages from
different vendors; 2) The model does not take into account the order of
messages necessarily so in a cloud environment where messages may arrive in
different orders, the model is still effective; and 3)  The model actively
retrains itself so manual re-training does not need to occur after system
updates.  The model was then tested in a cloud environment over a ninety day
period.  The authors reported a precision of 0.8 and a recall of 0.9, resulting
in an F-measure of 0.847.  

Fronza, et al.~\cite{fronza2013} introduced a pattern-recognition/classifier
hybrid approach that used an \ac{SVM} to detect patterns in log messages that
would lead to failure.  The authors used random indexing to solve the problem
previously discussed of \ac{SVM}s failing to classify two sequences as similar
if they are offset by one error report.  The authors report that their
predictor was able to almost perfectly detect non-failure conditions but was
poor at identifying failures.  The authors then weighted the \ac{SVM}s to
account for this discrepancy by assigning a larger penalty for false negatives
than false positives and had better results.

\subsection{Industry Approaches to \ac{OFP}} \label{industry}
Because hardware has become so easy to acquire, industry has sought to avoid
the problem of software failure by implementing massive redundancy in their
systems.  The work in~\cite{watanabe2014,irrera2015} attributes the problem
avoidance to the fact that until recently, implementing and maintaining a
failure predictor was difficult.  As we decrease the length of the software
development life cycle, software updates are being published with increasing
frequency leading to rapid changes in underlying systems.  These changes can
often render a predictor useless without re-training, which is often a manual
and resource intensive process.

Redundancy is not without problems however.  Implementing redundant systems to
avoid the failure problem can be expensive and can add overhead and complexity
making a system more difficult to manage.

\subsection{\ac{AFP} Framework} \label{afp}
The \ac{AFP} Framework by Irrera, et al.~\cite{irrera2015} shown in
Figure~\ref{fig:AFP}, presents a new approach to maintaining the efficacy of
failure predictors given underlying system changes.  The authors conducted a
case study implementing the framework using virtualization and fault injection
on a web server.  

\figAFP{0.8\textwidth}

The framework built upon past work by Irrera, et
al.~\cite{irrera2013,irrera2014} to generate failure data by injecting software
faults using a tool based on \ac{G-SWFIT}~\cite{gswfit} in a virtual
environment for comparing and automatically re-training predictors.  With the
introduction of the framework, Irrera, et al.~\cite{irrera2015} report results
of a case-study.  After implementing the \ac{AFP} using a web server and an
\ac{SVM} predictor, they report that their findings demonstrate their framework
is able to adapt to changes to an underlying system which would normally render
a predictor unusable.

In general, the use of simulated data is not well received by the community,
however the authors in~\cite{irrera2010,irrera2014} report evidence supporting
the claim that simulated failure data is representative of real failure data.
Further, the authors suggest that since systems are so frequently updated and
failures are in general rare events, real failure data is often not available.
Moreover, the literature shows that even if there is a certain type of failure
in training data and a predictor can detect and predict that type of error
accurately, it will still miss failures not present in the training data.  By
injecting the types of faults that one can expect, each failure type is
represented in the training data.

Irrera, et al.~\cite{irrera2015} reported good results and concluded that the
\ac{AFP} is an effective tool.  Unfortunately, the \ac{AFP} is not a universal
solution and requires significant work to be implemented on a modern \ac{MS}
Windows enterprise network.  Furthermore, the fault load previously explored
does not completely represent all possible failures~\cite{kikuchi2014}.

\section{Summary} \label{summary}
This chapter covered the definitions, measures of performance, and approaches
that are relevant to this research as organized under the subsection of
\emph{reporting} within the \ac{OFP} field of study.  There has been a
tremendous amount of research surrounding the topic of \ac{OFP} and many
prediction approaches have been presented.  Unfortunately, these approaches do
not appear on modern operational systems and failures are still relatively
prevalent.  Recent approaches as covered here have sought to make predictors
more adaptive to the changes in underlying systems in an effort to make
implementing existing failure predictors easier.  In this work, we plan to
extend the \ac{AFP} framework and further generalize the
approach.  
