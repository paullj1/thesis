As dependency upon computers grows, so too do the associated risks.  Computer
systems are all around us.  Some of these computer systems play insignificant
roles in our lives while others are responsible for sustaining our lives.
Unfortunately, the software that controls these systems is written by humans
and consequently subject to human error.  As a result, these systems are prone
to failure which in many cases may not be a big deal, but in others, could have
severe consequences.  Every day, critical infrastructure and Air Force missions
systems depend on the reliability of computer systems.  As a result, being able
to predict pending failure in computer systems can offer tremendous and
potentially life-saving applications in today's technologically advanced world.
While actually being able to accurately predict failure has unfortunately not
been proven possible, there has been work over the past several decades
attempting to make educated predictions about the failure of machines through
the use of machine learning algorithms~\cite{salfnerSurvey}.  Unfortunately,
much of this work has gone unused.  

There a number of ways to reduce the number of errors produced by a piece of
software, but the software development life-cycle is shrinking and less time
and effort are being devoted to reducing errors before deployment.  This leaves
real-time error prevention or handling.  In recent years, it seems many of the
cloud based computing companies have attempted to solve problems caused by
machine failure by making all of their services massively redundant.  As
hardware becomes more affordable, this is an effective approach in many ways,
but ultimately is still not cost efficient.  In some cases, funds may not be
available to achieve this sort of redundancy.  Consequently, this research
focuses on a small piece of the general field of reliable computing: online
failure prediction (OFP).  OFP is the act of attempting to predict when
failures are likely so that they can be avoided.  Chapter~\ref{chapter2}
outlines the recent work done in this field, much of which has gone
unimplemented due to the complex and manual task of training a prediction
model.  If the underlying system changes at all, the efficacy of a prediction
model can be drastically reduced if not rendered completely useless until it is
retrained.  Furthermore, training requires access to labelled training data.
Since failure is such a rare event, access to this type of training data may
not be possible.  

Irrera et al.~\cite{irrera2015} presented a potential solution in 2015 to
automate the process of dynamically generating failure data and using it to
train a predictor after an underlying system change.  They defined a framework
for implementing this process and called it the Adaptive Failure Prediction
(AFP) Framework.  This research explores an implementation of that framework.
More specifically, it presents results after implementing the AFP using a
Microsoft Windows Server domain controller.  Successive software updates are
then applied until the model selected becomes useless, the framework is then
allowed to re-train a new predictor.

\section{Problem Statement}
Predicting and alerting on impending network service failures currently uses
thresholds and rules on discrete items in enterprise system logs.  For example,
if the central processing unit (CPU) and memory usage on a device exceeds 90\%,
then an alert may be issued.  This approach works, but only for certain types
of failures and in order to minimize the false positives, it only makes
recommendations minutes before a failure, or when the system is in an already
degraded performance mode.  To maintain network resilience, the operational
organizations responsible for communications support desperately need some
means of gaining lead-time before a service failure occurs.  

Preceding a service failure event, multiple indicators spread disparate
sources, perhaps over a long period of time, may appear in system logs.  The
log entries of interest are also quite rare compared with normal operations.
Because of these constraints, identifying failure indicators can be nearly
impossible for humans to perform.  Further, in most cases, restoring service is
more important than identifying the indicators that may or may not have
existed.  

Failure prediction can be approached in several ways. The simplest approach is
to use everyday statistical analysis to, for example, determine the mean time
between failures of specific components. The analysis of all components making
up a system can be aggregated to make predictions about that system using a set
of statistics-based or business-relevant rules.  Unfortunately, the complexity
of modern architectures has outpaced such off-line statistical-based analysis,
which has driven the advancement of OFP.  OFP differs from other means of
failure prediction in that it focuses on classifying the current running state
of a machine as either failure prone or not, or in such a way that it describes
the confidence in how failure prone a system is at
present~\cite{salfnerSurvey}.

In recent years much of the work in OFP has gone unused due to the dramatic
decrease in cost and complexity involved in building hardware-based redundant
systems.  Furthermore, in most cases OFP implements machine learning algorithms
that require manual re-training after underlying system changes.  More
troubling is that system changes are becoming more frequent as the software
development life cycle moves toward a more continuous integration model.  To
help solve these challenges, the framework presented in~\cite{irrera2015} uses
simulated faults to automatically re-train a prediction algorithm to make
implementing OFP approaches easier.  This work extends that framework to
capture developments since its writing and generalize it so it works for a
broader class of devices by translating and implementing the fault injection
tool from the IA32 architecture to the x86-64 architecture and developing the
fault load to produce even more representative failures.

\section{Hypothesis}
The implementation of the AFP framework with a more representative fault load
for the Microsoft Windows enterprise infrastructure will lead to accurate
failure prediction with better lead time than is available today without any
prediction model.  This research will test this hypothesis by implementing the
AFP in a scaled virtual environment and evaluating its performance after
successive software updates.  Prior to this research, the implementation of the
AFP was not possible on modern Microsoft Windows infrastructure because the
fault injection tool had not been written for the x86-64 architecture.
Additionally, the faults produced and consequently predicted were the result of
first-order software failure.  This research evaluates the performance of the
AFP when second and third order failures are introduced.

\section{Research Goals}
The goal of this research is to inform decision makers about the potential
benefits of implementing a machine learning based failure prediction model to
predict failures in computer systems.  This research should demonstrate the
efficacy of the AFP framework and proposed extensions on the Microsoft Windows
enterprise architecture.  A long-term goal of this research is to drive the
improvement of the AFP framework and increase its adoption and resulting cost
savings.  In the near-term, the translation of the IA32 G-SWFIT tool to the
x86-64 architecture enables the same advantages of software fault injection for
32-bit systems on 64-bit systems~\cite{gswfit}.

\section{Impact of Research}
Every day, many of the Air Force's critical missions depend on our computer
infrastructure.  An essential piece of this infrastructure is the
authentication mechanisms that protect  sensitive information.
Unfortunately, the software at the core of this infrastructure is written and
maintained by humans and thus susceptible human error.  This research will
enable the Air Force and many others that use the Microsoft Enterprise
Infrastructure to accurately predict pending service outages thereby providing
lead-time in order to avoid those outages.  The result is cost savings in
personnel and equipment.  Further advantages are difficult to quantify such as
a decreased risk of mission failure due to network service outage.

\section{Assumptions and Limitations}
This research assumes indicators of failure are present and available with
enough lead-time to accurately make decisions and take mitigation action should
failure be predicted based on these indicators.  Furthermore, it has not been
proven possible to accurately predict future events without a priori knowledge.
This research presents a method of predicting failure, but this method is
completely useless at predicting \emph{act of God} events.  Further, this
method is capable of predicting system failure based on underlying software
failures and will unlikely provide any useful information about malicious
attacks against the target system.

\section{Results}
Because a prediction method is not presently deployed on any Air Force network,
any level of dependable prediction will be better than what is currently
available.  This research will show that after an underlying system change,
this method of predicting failure will be capable of automatically training a
more effective prediction algorithm so that this technique can be implemented
on an Air Force network with little to no impact on manpower.  Consequently, it
is expected that this research will inform decision makers and allow them to
implement this technique in a production environment.

Specifically, the technique presented in this research could most effectively
be implemented and used by the Cyber Security and Control System (CSCS) weapon
system employed at the 561st and 83d Network Operation Squadrons (NOS) and
their associated detachments to reduce the number of network service outages,
increasing uptime, leading to improved mission effectiveness in both the
support and operational domains.  Further, this technique should be general
enough to be employed outside of the Air Force to increase mission
effectiveness across the Department of Defense (DOD).  External to the DOD,
this research further generalizes an approach that could be used to help
increase availability of nearly any computer system.
